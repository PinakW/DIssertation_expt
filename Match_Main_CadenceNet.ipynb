{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PinakW/DIssertation_expt/blob/main/Match_Main_CadenceNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matched accuracy of float and quantized model"
      ],
      "metadata": {
        "id": "Nlxmmbxpot7m"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtuzdD-Y0hx9"
      },
      "source": [
        "TODO: Refer\n",
        "\n",
        "https://debuggercafe.com/getting-95-accuracy-on-the-caltech101-dataset-using-deep-learning/\n",
        "\n",
        "Data Pipeline:\n",
        "https://www.tensorflow.org/api_docs/python/tf/data/Dataset#as_numpy_iterator\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPUNbkOBLRGr"
      },
      "source": [
        "Loading the Caltech Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Q-XcSlHRLMMf"
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "#For plotting the dataset\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "#Data pipeline preparation\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "#model buildingZ\n",
        "from tensorflow.keras import models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9PJJVQvHaon"
      },
      "source": [
        "Code to get the number of samples per class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Habr8raqQY0C"
      },
      "source": [
        "Initially we will only try to train for 10 classes.\n",
        "\n",
        "https://github.com/tensorflow/datasets/issues/1923#issuecomment-1361608072"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "uriRoxiVHaIa"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = 10\n",
        "DataSet = 'caltech101'\n",
        "def num_samples_per_class(ds_train, get_top_10 = False, print_all = False):\n",
        "    vals = np.unique(np.fromiter(ds_train.map(lambda x, y: y), int), return_counts=True)\n",
        "    class_list = []\n",
        "    class_hist = []\n",
        "    for val,count in zip(*vals):\n",
        "        if print_all==True:\n",
        "            print(int(val), count)\n",
        "        #class_hist[val] = count\n",
        "        class_hist.append((val,count))\n",
        "    if get_top_10 == True:\n",
        "        sorted_tuple = sorted(class_hist, key=lambda t: t[-1], reverse=True)[:NUM_CLASSES]\n",
        "        class_list = [x for x,y in sorted_tuple]\n",
        "    return class_list\n",
        "\n",
        "def filter_fn(x, allowed_classes:list):\n",
        "    allowed_classes = tf.constant(allowed_classes)\n",
        "    isallowed = tf.equal(allowed_classes, tf.cast(x, allowed_classes.dtype))\n",
        "    reduced_sum = tf.reduce_sum(tf.cast(isallowed, tf.float32))\n",
        "    return tf.greater(reduced_sum, tf.constant(0.))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "4DETpDXuOIHT"
      },
      "outputs": [],
      "source": [
        "#(ds, ds_info) = tfds.load(DataSet, with_info=True, as_supervised=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "x3EBZDwjUBN9"
      },
      "outputs": [],
      "source": [
        "#ds_train, train_info = ds[\"train\"], ds_info.splits['train']\n",
        "#ds_test, test_info = ds[\"test\"], ds_info.splits['test']\n",
        "\n",
        "ds_train = tfds.load(DataSet, split='train + test[:75%]', as_supervised=True)\n",
        "ds_test = tfds.load(DataSet, split='test', as_supervised=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "zvgWBdGLTj4p"
      },
      "outputs": [],
      "source": [
        "class_list = num_samples_per_class(ds_train, get_top_10=True)\n",
        "class_list.sort()\n",
        "resized_ds_train = ds_train.filter(lambda x, y: filter_fn(y, class_list)) # as_supervised\n",
        "resized_ds_test = ds_test.filter(lambda x, y: filter_fn(y, class_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oCiprcJHMHO",
        "outputId": "83e993a2-405a-4d25-8b48-fef3685b63df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 611\n",
            "4 357\n",
            "9 104\n",
            "16 101\n",
            "37 335\n",
            "38 337\n",
            "54 92\n",
            "57 155\n",
            "66 625\n",
            "95 192\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "num_samples_per_class(resized_ds_train, print_all=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mj2yPwB6Tqnv",
        "outputId": "8b348f99-cb88-4213-e7a6-2c3cc10e0756"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 770\n",
            "4 437\n",
            "9 98\n",
            "16 93\n",
            "37 405\n",
            "38 405\n",
            "54 84\n",
            "57 170\n",
            "66 768\n",
            "95 209\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "num_samples_per_class(resized_ds_test, print_all=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prTD3lYBb1jk"
      },
      "source": [
        "Data Preprocessing\n",
        "\n",
        "We could use adapt() methods to get normlazation (feature wise) parameters. https://www.tensorflow.org/guide/keras/preprocessing_layers#the_adapt_method\n",
        "\n",
        "https://stackoverflow.com/questions/57657386/tensorflow-datasets-reshape-images\n",
        "\n",
        "\n",
        "MAINLY:\n",
        "https://www.tensorflow.org/datasets/keras_example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "24ab_2wmhw5X"
      },
      "outputs": [],
      "source": [
        "#Hyperparameters\n",
        "IMG_SIZE = 224\n",
        "NUM_CHANNELS = 3\n",
        "BATCH_SIZE=128\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xuc6xq51_uK6"
      },
      "source": [
        "Resizing and re-scaling images to a given dataset.\n",
        "Tutorial used: https://www.tensorflow.org/tutorials/images/data_augmentation\n",
        "\n",
        "For data pipeline you may also refer to\n",
        "https://github.com/tensorflow/datasets/issues/720"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ZVWbmo7eS-N2"
      },
      "outputs": [],
      "source": [
        "table = tf.lookup.StaticHashTable(\n",
        "    initializer=tf.lookup.KeyValueTensorInitializer(\n",
        "        keys=tf.constant(class_list, dtype=tf.int64),\n",
        "        values=tf.constant([0, 1, 2, 3, 4, 5, 6, 7, 8, 9],  dtype=tf.int64),\n",
        "    ),\n",
        "    default_value= tf.constant(0,  dtype=tf.int64)\n",
        ")\n",
        "\n",
        "@tf.function\n",
        "def map_func(label):\n",
        "    global class_list\n",
        "    mapped_label = table.lookup(label)\n",
        "    print(\"Label = \" + str(label) + \"\\t\" + \"Mapped Label = \" + str(mapped_label))\n",
        "    return mapped_label\n",
        "\n",
        "resize_and_rescale = tf.keras.Sequential([\n",
        "  layers.Resizing(IMG_SIZE, IMG_SIZE),\n",
        "  layers.Rescaling(1./255)\n",
        "])\n",
        "\n",
        "resize_layer = tf.keras.Sequential([\n",
        "  layers.Resizing(IMG_SIZE, IMG_SIZE),\n",
        "])\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  layers.RandomRotation(0.2),\n",
        "])\n",
        "\n",
        "#buffer_size = ds_info.splits['train'].num_examples      #Might return -2   https://stackoverflow.com/questions/50737192/tf-data-dataset-how-to-get-the-dataset-size-number-of-elements-in-an-epoch\n",
        "buffer_size = 30*NUM_CLASSES\n",
        "\n",
        "#resized_ds_train = filtered_ds_train.map(map_func, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "#https://www.tensorflow.org/tutorials/images/data_augmentation#apply_the_preprocessing_layers_to_the_datasets\n",
        "def prepare(ds, shuffle=False, augment=False, resize_only = False):\n",
        "    global buffer_size\n",
        "    global BATCH_SIZE\n",
        "    \n",
        "\n",
        "    # Resize and rescale all datasets.\n",
        "    if resize_only==True:\n",
        "        ds = ds.map(lambda x, y: (resize_layer(x), map_func(y)), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    else:\n",
        "        ds = ds.map(lambda x, y: (resize_and_rescale(x), map_func(y)), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    \n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size)\n",
        "        \n",
        "    # Batch all datasets.\n",
        "    #ds = ds.batch(BATCH_SIZE)\n",
        "\n",
        "    # Use data augmentation only on the training set.\n",
        "    if augment:\n",
        "        #f_ds = ds.filter(lambda x, y: filter_fn(y, [2,3,6]))    #[2,3,6] are the examples with lesser data. We are trying to bring back balance\n",
        "        #f_ds_aug = f_ds.map(lambda x, y: (data_augmentation(x, training=True), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "        #ds = ds.concatenate(f_ds_aug)\n",
        "        #ds_aug = ds.map(lambda x, y: (data_augmentation(x, training=True), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "        #ds = ds.concatenate(ds_aug)\n",
        "        ds_aug = ds.map(lambda x, y: (data_augmentation(x, training=True), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "        ds = ds.concatenate(ds_aug)\n",
        "\n",
        "        \n",
        "    # Use buffered prefetching on all datasets.\n",
        "    return ds.prefetch(buffer_size=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PxROybzWse8",
        "outputId": "e0310596-1d3b-4ae6-eb5e-27d3dee97ef7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label = Tensor(\"label:0\", shape=(), dtype=int64)\tMapped Label = Tensor(\"None_Lookup/LookupTableFindV2:0\", shape=(), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "resized_ds_train = prepare(resized_ds_train, augment=True)\n",
        "resized_ds_test = prepare(resized_ds_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZX5Sjv1T2JQ",
        "outputId": "88745af8-2137-405a-f891-580e76349ad7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 1222\n",
            "1 714\n",
            "2 208\n",
            "3 202\n",
            "4 670\n",
            "5 674\n",
            "6 184\n",
            "7 310\n",
            "8 1250\n",
            "9 384\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "num_samples_per_class(resized_ds_train, print_all=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQG4ddBvT21n",
        "outputId": "34e1c138-4793-4816-9e00-4bb900ba0963"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 770\n",
            "1 437\n",
            "2 98\n",
            "3 93\n",
            "4 405\n",
            "5 405\n",
            "6 84\n",
            "7 170\n",
            "8 768\n",
            "9 209\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "num_samples_per_class(resized_ds_test, print_all=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSpCep86OIfT"
      },
      "source": [
        "Prepare the model\n",
        "For Batchnorm, refer https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization\n",
        "\n",
        "Here they say that During training, the layer normalizes its output using the mean and standard deviation of the **current batch** of inputs.\n",
        "\n",
        "In order to make BatchNorm great, should we be using a larger batch as input?\n",
        "\n",
        "However, during Inference mode, the mean ans tsd deviation does not correspond to the current batch. Rather it is a moving mean and std dev of all the bacthes seen in training phase. (Thus, the parameters in inference phase for batch norm do not change)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "YuHhwzDITyz4"
      },
      "outputs": [],
      "source": [
        "input_shape = (IMG_SIZE,IMG_SIZE,NUM_CHANNELS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Mg41t1e5S8XA"
      },
      "outputs": [],
      "source": [
        "reg = tf.keras.regularizers.L1L2(l1=0.01, l2=0.01)\n",
        "model = models.Sequential()\n",
        "#model.add(resize_and_rescale)\n",
        "\n",
        "kernel_size = (5,5)\n",
        "model.add(layers.Conv2D(64, kernel_size, input_shape = input_shape, padding=\"same\", kernel_regularizer = reg))       #TODO: For instance, after a Conv2D layer with data_format=\"channels_first\", set axis=1 in BatchNormalization.\n",
        "model.add(layers.BatchNormalization())\n",
        "pool_size = (2,2)\n",
        "model.add(layers.MaxPool2D(pool_size))\n",
        "\n",
        "kernel_size = (3,3)\n",
        "model.add(layers.Conv2D(192, kernel_size, padding=\"same\", kernel_regularizer = reg))      #TODO: For instance, after a Conv2D layer with data_format=\"channels_first\", set axis=1 in BatchNormalization.\n",
        "model.add(layers.BatchNormalization())\n",
        "pool_size = (2,2)\n",
        "model.add(layers.MaxPool2D(pool_size))\n",
        "\n",
        "kernel_size = (3,3)\n",
        "model.add(layers.Conv2D(64, kernel_size, padding=\"same\", kernel_regularizer = reg))       #TODO: For instance, after a Conv2D layer with data_format=\"channels_first\", set axis=1 in BatchNormalization.\n",
        "model.add(layers.BatchNormalization())\n",
        "pool_size = (2,2)\n",
        "model.add(layers.MaxPool2D(pool_size))\n",
        "\n",
        "kernel_size = (3,3)\n",
        "model.add(layers.Conv2D(128, kernel_size, padding=\"same\", kernel_regularizer = reg))      #TODO: For instance, after a Conv2D layer with data_format=\"channels_first\", set axis=1 in BatchNormalization.\n",
        "model.add(layers.BatchNormalization())\n",
        "pool_size = (2,2)\n",
        "model.add(layers.MaxPool2D(pool_size))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(1000, kernel_regularizer = reg))\n",
        "\n",
        "model.add(layers.Dense(NUM_CLASSES, activation='softmax', kernel_regularizer = reg))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-PFEc55hxNm",
        "outputId": "7f1462ab-ff21-4db3-fd63-afd9b6d3c5e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 224, 224, 64)      4864      \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 224, 224, 64)     256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 112, 112, 64)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 112, 112, 192)     110784    \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 112, 112, 192)    768       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 56, 56, 192)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 56, 56, 64)        110656    \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 56, 56, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 28, 28, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 28, 28, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 28, 28, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 14, 14, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1000)              25089000  \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                10010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,400,962\n",
            "Trainable params: 25,400,066\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "Learning_Rate = 1e-5                                            #https://machinelearningmastery.com/understand-the-dynamics-of-learning-rate-on-deep-learning-neural-networks/\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=Learning_Rate)     #OR tf.keras.optimizers.SGD(learning_rate=Learning_Rate, momentum=0.0)\n",
        "#model.compile( optimizer = opt, loss = 'sparse_categorical_crossentropy', metrics=['accuracy'] )\n",
        "model.compile( optimizer = opt, loss = 'sparse_categorical_crossentropy', metrics=['accuracy'] )\n",
        "\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh35uw-5keV2"
      },
      "source": [
        "Reference: https://github.com/tensorflow/datasets/issues/720"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "yUisIOtOiKHV"
      },
      "outputs": [],
      "source": [
        "#resized_ds_train = resized_ds_train.cache()\n",
        "\n",
        "#resized_ds_train = resized_ds_train.shuffle(buffer_size)\n",
        "resized_ds_train = resized_ds_train.batch(BATCH_SIZE)\n",
        "resized_ds_test = resized_ds_test.batch(BATCH_SIZE)\n",
        "#resized_ds_train = resized_ds_train.prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20Xb1Xb65V6N"
      },
      "source": [
        "Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFL849PI32M3",
        "outputId": "0a25ae82-f2c4-4a22-af6b-d2441ed80dcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "46/46 [==============================] - 40s 846ms/step - loss: 1962.7389 - accuracy: 0.4990\n",
            "Epoch 2/10\n",
            "46/46 [==============================] - 36s 789ms/step - loss: 1858.7561 - accuracy: 0.5859\n",
            "Epoch 3/10\n",
            "46/46 [==============================] - 36s 781ms/step - loss: 1755.4932 - accuracy: 0.6210\n",
            "Epoch 4/10\n",
            "46/46 [==============================] - 36s 785ms/step - loss: 1654.3737 - accuracy: 0.6482\n",
            "Epoch 5/10\n",
            "46/46 [==============================] - 36s 782ms/step - loss: 1555.8053 - accuracy: 0.6750\n",
            "Epoch 6/10\n",
            "46/46 [==============================] - 36s 787ms/step - loss: 1460.0342 - accuracy: 0.6901\n",
            "Epoch 7/10\n",
            "46/46 [==============================] - 36s 780ms/step - loss: 1367.1528 - accuracy: 0.7143\n",
            "Epoch 8/10\n",
            "46/46 [==============================] - 36s 781ms/step - loss: 1277.2706 - accuracy: 0.7320\n",
            "Epoch 9/10\n",
            "46/46 [==============================] - 36s 778ms/step - loss: 1190.4412 - accuracy: 0.7399\n",
            "Epoch 10/10\n",
            "46/46 [==============================] - 36s 782ms/step - loss: 1106.6735 - accuracy: 0.7549\n"
          ]
        }
      ],
      "source": [
        "h = model.fit( resized_ds_train, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAslbj3d5T8_",
        "outputId": "3f0dad18-8ec5-497a-835c-f0acfa11bba1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 8s 304ms/step - loss: 1064.6818 - accuracy: 0.6909\n"
          ]
        }
      ],
      "source": [
        "loss,acc = model.evaluate(resized_ds_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ret_as_numpy():\n",
        "    test = tfds.load(DataSet, split='test', as_supervised=True)\n",
        "    test = prepare(test)\n",
        "    test = tfds.as_numpy(test)\n",
        "    return test"
      ],
      "metadata": {
        "id": "wyxm51ZxB2iW"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_float_model(model, test):\n",
        "    test_labels = []\n",
        "    \n",
        "    # Run predictions on every image in the \"test\" dataset.\n",
        "    prediction_digits = []\n",
        "    for i, test_example in enumerate(test):\n",
        "        if i % 1000 == 0:\n",
        "            print('Evaluated on {n} results so far.'.format(n=i))\n",
        "        test_labels.append(test_example[-1])\n",
        "        test_image = test_example[0]\n",
        "        # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "        # the model's input data format.\n",
        "        #display(test_image.shape)\n",
        "        test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "        #test_image = np.expand_dims(test_image, axis=3).astype(np.float32)\n",
        "        #display(test_image.shape)\n",
        "        \n",
        "        # Run inference.\n",
        "        output = model(test_image, training=False)\n",
        "        # Post-processing: remove batch dimension and find the digit with highest\n",
        "        # probability.\n",
        "        output = output.numpy()\n",
        "        #display(output[0])\n",
        "        digit = np.argmax(output[0])\n",
        "        prediction_digits.append(digit)\n",
        "        \n",
        "    print('\\n')\n",
        "    # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "    #display(prediction_digits)\n",
        "    #display(test_labels)\n",
        "    prediction_digits = np.array(prediction_digits)\n",
        "    accuracy = (prediction_digits == test_labels).mean()\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "hzBBnzSSBWI8"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_as_np = ret_as_numpy()"
      ],
      "metadata": {
        "id": "g0tcEzipg4K7"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRXaWhGgnLV8",
        "outputId": "c9a35aa0-9078-49a4-b07c-78135da7877e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluated on 0 results so far.\n",
            "Evaluated on 1000 results so far.\n",
            "Evaluated on 2000 results so far.\n",
            "Evaluated on 3000 results so far.\n",
            "Evaluated on 4000 results so far.\n",
            "Evaluated on 5000 results so far.\n",
            "Evaluated on 6000 results so far.\n",
            "\n",
            "\n",
            "Float test_accuracy: 0.41140696909927676\n"
          ]
        }
      ],
      "source": [
        "test_accuracy = evaluate_float_model(model, test_as_np)\n",
        "\n",
        "print('Float test_accuracy:', test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDw2jJ1gvvIi"
      },
      "source": [
        "Model trained. Now we will create float as well as quantized model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "_PkqxcV8yL8A"
      },
      "outputs": [],
      "source": [
        "! pip install -q tensorflow-model-optimization\n",
        "import tensorflow_model_optimization as tfmot\n",
        "quantize_model = tfmot.quantization.keras.quantize_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAOVonnhv1aR",
        "outputId": "89a1f95e-ab99-484a-d3e7-eaaa8026cce9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " quantize_layer (QuantizeLay  (None, 224, 224, 3)      3         \n",
            " er)                                                             \n",
            "                                                                 \n",
            " quant_conv2d_4 (QuantizeWra  (None, 224, 224, 64)     4993      \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            " quant_batch_normalization_4  (None, 224, 224, 64)     259       \n",
            "  (QuantizeWrapperV2)                                            \n",
            "                                                                 \n",
            " quant_max_pooling2d_4 (Quan  (None, 112, 112, 64)     1         \n",
            " tizeWrapperV2)                                                  \n",
            "                                                                 \n",
            " quant_conv2d_5 (QuantizeWra  (None, 112, 112, 192)    111169    \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            " quant_batch_normalization_5  (None, 112, 112, 192)    771       \n",
            "  (QuantizeWrapperV2)                                            \n",
            "                                                                 \n",
            " quant_max_pooling2d_5 (Quan  (None, 56, 56, 192)      1         \n",
            " tizeWrapperV2)                                                  \n",
            "                                                                 \n",
            " quant_conv2d_6 (QuantizeWra  (None, 56, 56, 64)       110785    \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            " quant_batch_normalization_6  (None, 56, 56, 64)       259       \n",
            "  (QuantizeWrapperV2)                                            \n",
            "                                                                 \n",
            " quant_max_pooling2d_6 (Quan  (None, 28, 28, 64)       1         \n",
            " tizeWrapperV2)                                                  \n",
            "                                                                 \n",
            " quant_conv2d_7 (QuantizeWra  (None, 28, 28, 128)      74113     \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            " quant_batch_normalization_7  (None, 28, 28, 128)      515       \n",
            "  (QuantizeWrapperV2)                                            \n",
            "                                                                 \n",
            " quant_max_pooling2d_7 (Quan  (None, 14, 14, 128)      1         \n",
            " tizeWrapperV2)                                                  \n",
            "                                                                 \n",
            " quant_flatten_1 (QuantizeWr  (None, 25088)            1         \n",
            " apperV2)                                                        \n",
            "                                                                 \n",
            " quant_dense_2 (QuantizeWrap  (None, 1000)             25089005  \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            " quant_dense_3 (QuantizeWrap  (None, 10)               10015     \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,401,892\n",
            "Trainable params: 25,400,066\n",
            "Non-trainable params: 1,826\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "q_aware_model = quantize_model(model)\n",
        "#q_aware_model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
        "q_aware_model.compile(optimizer = opt, loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "q_aware_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "ttJjDT4fxypo"
      },
      "outputs": [],
      "source": [
        "quantize_train, quant_train_info = tfds.load(DataSet, split='train + test[:75%]', with_info=True, as_supervised=True)\n",
        "filtered_quantize_train = quantize_train.filter(lambda x, y: filter_fn(y, class_list))\n",
        "#resized_quantize_train = prepare(filtered_quantize_train, resize_only=True)\n",
        "resized_quantize_train = prepare(filtered_quantize_train)\n",
        "\n",
        "#fig = tfds.show_examples(resized_quantize_train, ds_info)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Au1jzJfrBxNO",
        "outputId": "85067178-c3af-42b3-9143-895066013ca2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "23/23 [==============================] - 30s 1s/step - loss: 998.1990 - accuracy: 0.8402\n",
            "Epoch 2/5\n",
            "23/23 [==============================] - 21s 916ms/step - loss: 857.1569 - accuracy: 0.8505\n",
            "Epoch 3/5\n",
            "23/23 [==============================] - 21s 904ms/step - loss: 750.5754 - accuracy: 0.8597\n",
            "Epoch 4/5\n",
            "23/23 [==============================] - 22s 934ms/step - loss: 667.1239 - accuracy: 0.8677\n",
            "Epoch 5/5\n",
            "23/23 [==============================] - 21s 912ms/step - loss: 597.9076 - accuracy: 0.8697\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f13b5808af0>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "resized_quantize_train = resized_quantize_train.batch(BATCH_SIZE)\n",
        "q_aware_model.fit(resized_quantize_train, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQ5TWSxVzIIL",
        "outputId": "6532546e-309d-4671-ea4b-3cceee67ec56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_4_layer_call_fn, conv2d_4_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, conv2d_5_layer_call_fn, conv2d_5_layer_call_and_return_conditional_losses while saving (showing 5 of 18). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "quantized_tflite_model = converter.convert()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5FUhkwN3hQ_"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(interpreter, test):\n",
        "    test_labels = []\n",
        "\n",
        "\n",
        "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "    \n",
        "    # Run predictions on every image in the \"test\" dataset.\n",
        "    prediction_digits = []\n",
        "    for i, test_example in enumerate(test):\n",
        "        if i % 1000 == 0:\n",
        "            print('Evaluated on {n} results so far.'.format(n=i))\n",
        "        test_labels.append(test_example[-1])\n",
        "        test_image = test_example[0]\n",
        "        # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "        # the model's input data format.\n",
        "        #display(test_image.shape)\n",
        "        test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "        #test_image = np.expand_dims(test_image, axis=3).astype(np.float32)\n",
        "        #display(test_image.shape)\n",
        "        interpreter.set_tensor(input_index, test_image)\n",
        "        \n",
        "        # Run inference.\n",
        "        interpreter.invoke()\n",
        "        \n",
        "        # Post-processing: remove batch dimension and find the digit with highest\n",
        "        # probability.\n",
        "        output = interpreter.tensor(output_index)\n",
        "        digit = np.argmax(output()[0])\n",
        "        prediction_digits.append(digit)\n",
        "        \n",
        "    print('\\n')\n",
        "    # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "    prediction_digits = np.array(prediction_digits)\n",
        "    accuracy = (prediction_digits == test_labels).mean()\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AkK4auuayiV"
      },
      "source": [
        "Define evaluator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGd2iDPuRWZ8"
      },
      "source": [
        "Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Fj2J-4RRYvd"
      },
      "outputs": [],
      "source": [
        "#Models obtained from TfLiteConverter can be run in Python with Interpreter.\n",
        "interpreter = tf.lite.Interpreter(model_content=quantized_tflite_model)\n",
        "#Since TensorFlow Lite pre-plans tensor allocations to optimize inference, the user needs to call allocate_tensors() before any inference.\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "test_accuracy = evaluate_model(interpreter, test_as_np)\n",
        "\n",
        "print('Quant TFLite test_accuracy:', test_accuracy)\n",
        "#print('Quant TF test accuracy:', q_aware_model_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6k1Pdc-2xmX"
      },
      "source": [
        "Save the Float model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cna44KG62VL3"
      },
      "outputs": [],
      "source": [
        "MODEL_DIR = \"CadenceNet_Float\"\n",
        "model.save(MODEL_DIR, save_format=\"tf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Za8NOpnC3P7p"
      },
      "outputs": [],
      "source": [
        "#convert to onnx\n",
        "!pip install -U tf2onnx\n",
        "!python -m tf2onnx.convert --saved-model /content/CadenceNet_Float/ --output /content/CadenceNet_Float_sparseCrossEntropy.onnx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-KO0PW93dB3"
      },
      "source": [
        "Save QAT model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4N_Z-Yev3e4o"
      },
      "outputs": [],
      "source": [
        "quant_file = \"/content/quantized_model_sparseCrossEntropy_Rescaled.tflite\"\n",
        "open(quant_file, \"wb\").write(quantized_tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PL_9KH5oLzV2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}