{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PinakW/DIssertation_expt/blob/main/Match_Main_CadenceNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPUNbkOBLRGr"
      },
      "source": [
        "#Loading the Caltech Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Q-XcSlHRLMMf"
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "#For plotting the dataset\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "#Data pipeline preparation\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "#model buildingZ\n",
        "from tensorflow.keras import models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9PJJVQvHaon"
      },
      "source": [
        "Code to get the number of samples per class.\n",
        "We will only try to train for 10 classes for which we have good enough data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "uriRoxiVHaIa"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = 10\n",
        "DataSet = 'caltech101'\n",
        "def num_samples_per_class(ds_train, get_top_10 = False, print_all = False):\n",
        "    vals = np.unique(np.fromiter(ds_train.map(lambda x, y: y), int), return_counts=True)\n",
        "    class_list = []\n",
        "    class_hist = []\n",
        "    for val,count in zip(*vals):\n",
        "        if print_all==True:\n",
        "            print(int(val), count)\n",
        "        class_hist.append((val,count))\n",
        "    if get_top_10 == True:\n",
        "        sorted_tuple = sorted(class_hist, key=lambda t: t[-1], reverse=True)[:NUM_CLASSES]\n",
        "        class_list = [x for x,y in sorted_tuple]\n",
        "    return class_list\n",
        "\n",
        "def filter_fn(x, allowed_classes:list):\n",
        "    allowed_classes = tf.constant(allowed_classes)\n",
        "    isallowed = tf.equal(allowed_classes, tf.cast(x, allowed_classes.dtype))\n",
        "    reduced_sum = tf.reduce_sum(tf.cast(isallowed, tf.float32))\n",
        "    return tf.greater(reduced_sum, tf.constant(0.))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Habr8raqQY0C"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "x3EBZDwjUBN9"
      },
      "outputs": [],
      "source": [
        "ds_train = tfds.load(DataSet, split='train + test[:75%]', as_supervised=True)\n",
        "ds_test = tfds.load(DataSet, split='test', as_supervised=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "zvgWBdGLTj4p"
      },
      "outputs": [],
      "source": [
        "class_list = num_samples_per_class(ds_train, get_top_10=True)\n",
        "class_list.sort()\n",
        "resized_ds_train = ds_train.filter(lambda x, y: filter_fn(y, class_list)) # as_supervised\n",
        "resized_ds_test = ds_test.filter(lambda x, y: filter_fn(y, class_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oCiprcJHMHO",
        "outputId": "4fc5e9ef-c69f-4a24-e8b8-c4b90f13d310"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 611\n",
            "4 357\n",
            "9 104\n",
            "16 101\n",
            "37 335\n",
            "38 337\n",
            "54 92\n",
            "57 155\n",
            "66 625\n",
            "95 192\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "num_samples_per_class(resized_ds_train, print_all=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mj2yPwB6Tqnv",
        "outputId": "f285b515-fc72-4dfc-8c05-b499200f5808"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 770\n",
            "4 437\n",
            "9 98\n",
            "16 93\n",
            "37 405\n",
            "38 405\n",
            "54 84\n",
            "57 170\n",
            "66 768\n",
            "95 209\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "num_samples_per_class(resized_ds_test, print_all=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prTD3lYBb1jk"
      },
      "source": [
        "#Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "24ab_2wmhw5X"
      },
      "outputs": [],
      "source": [
        "#Hyperparameters\n",
        "IMG_SIZE = 224\n",
        "NUM_CHANNELS = 3\n",
        "BATCH_SIZE=128\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xuc6xq51_uK6"
      },
      "source": [
        "We will create efficient input data pipelines so that we use resources effectively"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ZVWbmo7eS-N2"
      },
      "outputs": [],
      "source": [
        "#Relabelling to avoid issues. Note that human readability is reduced by this\n",
        "table = tf.lookup.StaticHashTable(\n",
        "    initializer=tf.lookup.KeyValueTensorInitializer(\n",
        "        keys=tf.constant(class_list, dtype=tf.int64),\n",
        "        values=tf.constant([0, 1, 2, 3, 4, 5, 6, 7, 8, 9],  dtype=tf.int64),\n",
        "    ),\n",
        "    default_value= tf.constant(0,  dtype=tf.int64)\n",
        ")\n",
        "\n",
        "#This function will be used in the graph execution hence @tf.function prefix\n",
        "@tf.function\n",
        "def map_func(label):\n",
        "    global class_list\n",
        "    mapped_label = table.lookup(label)\n",
        "    print(\"Label = \" + str(label) + \"\\t\" + \"Mapped Label = \" + str(mapped_label))\n",
        "    return mapped_label\n",
        "\n",
        "#Preprocessing done as part of the graph\n",
        "resize_and_rescale = tf.keras.Sequential([\n",
        "  layers.Resizing(IMG_SIZE, IMG_SIZE),\n",
        "  layers.Rescaling(1./255)\n",
        "])\n",
        "\n",
        "resize_layer = tf.keras.Sequential([\n",
        "  layers.Resizing(IMG_SIZE, IMG_SIZE),\n",
        "])\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  layers.RandomRotation(0.2),\n",
        "])\n",
        "\n",
        "buffer_size = 30*NUM_CLASSES\n",
        "\n",
        "#Preprocessing function which invokes above graphs\n",
        "def prepare(ds, shuffle=False, augment=False, resize_only = False):\n",
        "    global buffer_size\n",
        "    global BATCH_SIZE\n",
        "    \n",
        "\n",
        "    # Resize and rescale all datasets.\n",
        "    if resize_only==True:\n",
        "        ds = ds.map(lambda x, y: (resize_layer(x), map_func(y)), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    else:\n",
        "        ds = ds.map(lambda x, y: (resize_and_rescale(x), map_func(y)), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    \n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size)\n",
        "        \n",
        "    # Batch all datasets.\n",
        "    #ds = ds.batch(BATCH_SIZE)\n",
        "\n",
        "    # Use data augmentation only on the training set.\n",
        "    if augment:\n",
        "        #f_ds = ds.filter(lambda x, y: filter_fn(y, [2,3,6]))    #[2,3,6] are the examples with lesser data. We are trying to bring back balance\n",
        "        #f_ds_aug = f_ds.map(lambda x, y: (data_augmentation(x, training=True), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "        #ds = ds.concatenate(f_ds_aug)\n",
        "        #ds_aug = ds.map(lambda x, y: (data_augmentation(x, training=True), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "        #ds = ds.concatenate(ds_aug)\n",
        "        ds_aug = ds.map(lambda x, y: (data_augmentation(x, training=True), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "        ds = ds.concatenate(ds_aug)\n",
        "\n",
        "        \n",
        "    # Use buffered prefetching on all datasets.\n",
        "    return ds.prefetch(buffer_size=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PxROybzWse8",
        "outputId": "d4911d03-1017-4164-ad7f-55621a401a72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label = Tensor(\"label:0\", shape=(), dtype=int64)\tMapped Label = Tensor(\"None_Lookup/LookupTableFindV2:0\", shape=(), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "resized_ds_train = prepare(resized_ds_train, augment=True)\n",
        "resized_ds_test = prepare(resized_ds_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After pre-processing and data augmentation, display the new dataset"
      ],
      "metadata": {
        "id": "3lUqW0edcbFg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZX5Sjv1T2JQ",
        "outputId": "f9379e49-8663-42e7-c5c5-649e57861e17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 1222\n",
            "1 714\n",
            "2 208\n",
            "3 202\n",
            "4 670\n",
            "5 674\n",
            "6 184\n",
            "7 310\n",
            "8 1250\n",
            "9 384\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "num_samples_per_class(resized_ds_train, print_all=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQG4ddBvT21n",
        "outputId": "26e08c32-ba19-4da1-df56-d6357b8d9070"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 770\n",
            "1 437\n",
            "2 98\n",
            "3 93\n",
            "4 405\n",
            "5 405\n",
            "6 84\n",
            "7 170\n",
            "8 768\n",
            "9 209\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "num_samples_per_class(resized_ds_test, print_all=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSpCep86OIfT"
      },
      "source": [
        "#Prepare the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "YuHhwzDITyz4"
      },
      "outputs": [],
      "source": [
        "input_shape = (IMG_SIZE,IMG_SIZE,NUM_CHANNELS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Mg41t1e5S8XA"
      },
      "outputs": [],
      "source": [
        "reg = tf.keras.regularizers.L2(0.01)\n",
        "model = models.Sequential()\n",
        "#model.add(resize_and_rescale)\n",
        "\n",
        "kernel_size = (5,5)\n",
        "model.add(layers.Conv2D(32, kernel_size, input_shape = input_shape, padding=\"same\", kernel_regularizer = reg))       #TODO: For instance, after a Conv2D layer with data_format=\"channels_first\", set axis=1 in BatchNormalization.\n",
        "model.add(layers.BatchNormalization())\n",
        "pool_size = (2,2)\n",
        "model.add(layers.MaxPool2D(pool_size))\n",
        "\n",
        "kernel_size = (3,3)\n",
        "model.add(layers.Conv2D(64, kernel_size, padding=\"same\", kernel_regularizer = reg))      #TODO: For instance, after a Conv2D layer with data_format=\"channels_first\", set axis=1 in BatchNormalization.\n",
        "model.add(layers.BatchNormalization())\n",
        "pool_size = (2,2)\n",
        "model.add(layers.MaxPool2D(pool_size))\n",
        "\n",
        "kernel_size = (3,3)\n",
        "model.add(layers.Conv2D(128, kernel_size, padding=\"same\", kernel_regularizer = reg))       #TODO: For instance, after a Conv2D layer with data_format=\"channels_first\", set axis=1 in BatchNormalization.\n",
        "model.add(layers.BatchNormalization())\n",
        "pool_size = (2,2)\n",
        "model.add(layers.MaxPool2D(pool_size))\n",
        "\n",
        "kernel_size = (3,3)\n",
        "model.add(layers.Conv2D(192, kernel_size, padding=\"same\", kernel_regularizer = reg))      #TODO: For instance, after a Conv2D layer with data_format=\"channels_first\", set axis=1 in BatchNormalization.\n",
        "model.add(layers.BatchNormalization())\n",
        "pool_size = (2,2)\n",
        "model.add(layers.MaxPool2D(pool_size))\n",
        "\n",
        "kernel_size = (3,3)\n",
        "model.add(layers.Conv2D(64, kernel_size, padding=\"same\", kernel_regularizer = reg))      #TODO: For instance, after a Conv2D layer with data_format=\"channels_first\", set axis=1 in BatchNormalization.\n",
        "model.add(layers.BatchNormalization())\n",
        "pool_size = (2,2)\n",
        "model.add(layers.MaxPool2D(pool_size))\n",
        "\n",
        "kernel_size = (3,3)\n",
        "model.add(layers.Conv2D(32, kernel_size, padding=\"same\", kernel_regularizer = reg))      #TODO: For instance, after a Conv2D layer with data_format=\"channels_first\", set axis=1 in BatchNormalization.\n",
        "model.add(layers.BatchNormalization())\n",
        "pool_size = (2,2)\n",
        "model.add(layers.MaxPool2D(pool_size))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(.2))\n",
        "model.add(layers.Dense(1000, kernel_regularizer = reg))\n",
        "model.add(layers.Dropout(.02))\n",
        "model.add(layers.Dense(NUM_CLASSES, activation='softmax', kernel_regularizer = reg))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-PFEc55hxNm",
        "outputId": "bc22853b-9809-4742-cda9-16bb8e83f49c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 224, 224, 32)      2432      \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 224, 224, 32)     128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 112, 112, 32)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 112, 112, 64)      18496     \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 112, 112, 64)     256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 56, 56, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 56, 56, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 56, 56, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 28, 28, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 28, 28, 192)       221376    \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 28, 28, 192)      768       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 14, 14, 192)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 14, 14, 64)        110656    \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 14, 14, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 7, 7, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 7, 7, 32)          18464     \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 7, 7, 32)         128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 3, 3, 32)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 288)               0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 288)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1000)              289000    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 1000)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                10010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 746,338\n",
            "Trainable params: 745,314\n",
            "Non-trainable params: 1,024\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "Learning_Rate = 1e-5                                            #https://machinelearningmastery.com/understand-the-dynamics-of-learning-rate-on-deep-learning-neural-networks/\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=Learning_Rate)     #OR tf.keras.optimizers.SGD(learning_rate=Learning_Rate, momentum=0.0)\n",
        "#model.compile( optimizer = opt, loss = 'sparse_categorical_crossentropy', metrics=['accuracy'] )\n",
        "model.compile( optimizer = opt, loss = 'sparse_categorical_crossentropy', metrics=['accuracy'] )\n",
        "\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh35uw-5keV2"
      },
      "source": [
        "Reference: https://github.com/tensorflow/datasets/issues/720"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "yUisIOtOiKHV"
      },
      "outputs": [],
      "source": [
        "resized_ds_train = resized_ds_train.batch(BATCH_SIZE)\n",
        "resized_ds_test = resized_ds_test.batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20Xb1Xb65V6N"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFL849PI32M3",
        "outputId": "dfdfbffd-3f44-40f3-c6ee-4a1bb77a5264"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "46/46 [==============================] - 25s 527ms/step - loss: 11.0448 - accuracy: 0.2946\n",
            "Epoch 2/10\n",
            "46/46 [==============================] - 24s 529ms/step - loss: 10.4526 - accuracy: 0.5138\n",
            "Epoch 3/10\n",
            "46/46 [==============================] - 24s 530ms/step - loss: 10.2307 - accuracy: 0.5828\n",
            "Epoch 4/10\n",
            "46/46 [==============================] - 25s 547ms/step - loss: 10.0710 - accuracy: 0.6310\n",
            "Epoch 5/10\n",
            "46/46 [==============================] - 24s 531ms/step - loss: 9.9494 - accuracy: 0.6595\n",
            "Epoch 6/10\n",
            "46/46 [==============================] - 24s 530ms/step - loss: 9.8553 - accuracy: 0.6808\n",
            "Epoch 7/10\n",
            "46/46 [==============================] - 24s 530ms/step - loss: 9.7696 - accuracy: 0.6982\n",
            "Epoch 8/10\n",
            "46/46 [==============================] - 24s 528ms/step - loss: 9.6916 - accuracy: 0.7111\n",
            "Epoch 9/10\n",
            "46/46 [==============================] - 24s 531ms/step - loss: 9.6253 - accuracy: 0.7246\n",
            "Epoch 10/10\n",
            "46/46 [==============================] - 24s 527ms/step - loss: 9.5634 - accuracy: 0.7367\n"
          ]
        }
      ],
      "source": [
        "h = model.fit( resized_ds_train, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAslbj3d5T8_",
        "outputId": "d4d8ea70-7289-4c4e-82a4-6dae6160a783"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 4s 141ms/step - loss: 9.7233 - accuracy: 0.6609\n"
          ]
        }
      ],
      "source": [
        "loss,acc = model.evaluate(resized_ds_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluation functions (Self defined)"
      ],
      "metadata": {
        "id": "6k9Czx1XdIAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ret_as_numpy():\n",
        "    test = tfds.load(DataSet, split='test', as_supervised=True)\n",
        "    test = prepare(test)\n",
        "    test = tfds.as_numpy(test)\n",
        "    return test"
      ],
      "metadata": {
        "id": "wyxm51ZxB2iW"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Float accuracy"
      ],
      "metadata": {
        "id": "0ymH39V1dN13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_float_model(model, test):\n",
        "    test_labels = []\n",
        "    \n",
        "    # Run predictions on every image in the \"test\" dataset.\n",
        "    prediction_digits = []\n",
        "    for i, test_example in enumerate(test):\n",
        "        if i % 1000 == 0:\n",
        "            print('Evaluated on {n} results so far.'.format(n=i))\n",
        "        test_labels.append(test_example[-1])\n",
        "        test_image = test_example[0]\n",
        "        # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "        # the model's input data format.\n",
        "        #display(test_image.shape)\n",
        "        test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "        #test_image = np.expand_dims(test_image, axis=3).astype(np.float32)\n",
        "        #display(test_image.shape)\n",
        "        \n",
        "        # Run inference.\n",
        "        output = model(test_image, training=False)\n",
        "        # Post-processing: remove batch dimension and find the digit with highest\n",
        "        # probability.\n",
        "        output = output.numpy()\n",
        "        #display(output[0])\n",
        "        digit = np.argmax(output[0])\n",
        "        prediction_digits.append(digit)\n",
        "        \n",
        "    print('\\n')\n",
        "    # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "    #display(prediction_digits)\n",
        "    #display(test_labels)\n",
        "    prediction_digits = np.array(prediction_digits)\n",
        "    accuracy = (prediction_digits == test_labels).mean()\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "hzBBnzSSBWI8"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_as_np = ret_as_numpy()"
      ],
      "metadata": {
        "id": "g0tcEzipg4K7"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRXaWhGgnLV8",
        "outputId": "3ad7cce1-2df5-4d26-fd39-ccd63b298324"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluated on 0 results so far.\n",
            "Evaluated on 1000 results so far.\n",
            "Evaluated on 2000 results so far.\n",
            "Evaluated on 3000 results so far.\n",
            "Evaluated on 4000 results so far.\n",
            "Evaluated on 5000 results so far.\n",
            "Evaluated on 6000 results so far.\n",
            "\n",
            "\n",
            "Float test_accuracy: 0.653517422748192\n"
          ]
        }
      ],
      "source": [
        "test_accuracy = evaluate_float_model(model, test_as_np)\n",
        "\n",
        "print('Float test_accuracy:', test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDw2jJ1gvvIi"
      },
      "source": [
        "#Create and Train Quantize model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Create Quantization with default quantization rules."
      ],
      "metadata": {
        "id": "P5lQYdIPdX-Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "_PkqxcV8yL8A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f537976e-2f6e-41f4-fbc3-23bc45255376"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/238.9 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.9/238.9 KB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "! pip install -q tensorflow-model-optimization\n",
        "import tensorflow_model_optimization as tfmot\n",
        "quantize_model = tfmot.quantization.keras.quantize_model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###We need to re-train the quantized model on training set"
      ],
      "metadata": {
        "id": "64xWZbthdqGK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAOVonnhv1aR",
        "outputId": "c577ed77-e3dc-44eb-b296-8af49bc48926"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " quantize_layer (QuantizeLay  (None, 224, 224, 3)      3         \n",
            " er)                                                             \n",
            "                                                                 \n",
            " quant_conv2d_6 (QuantizeWra  (None, 224, 224, 32)     2497      \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            " quant_batch_normalization_6  (None, 224, 224, 32)     131       \n",
            "  (QuantizeWrapperV2)                                            \n",
            "                                                                 \n",
            " quant_max_pooling2d_6 (Quan  (None, 112, 112, 32)     1         \n",
            " tizeWrapperV2)                                                  \n",
            "                                                                 \n",
            " quant_conv2d_7 (QuantizeWra  (None, 112, 112, 64)     18625     \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            " quant_batch_normalization_7  (None, 112, 112, 64)     259       \n",
            "  (QuantizeWrapperV2)                                            \n",
            "                                                                 \n",
            " quant_max_pooling2d_7 (Quan  (None, 56, 56, 64)       1         \n",
            " tizeWrapperV2)                                                  \n",
            "                                                                 \n",
            " quant_conv2d_8 (QuantizeWra  (None, 56, 56, 128)      74113     \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            " quant_batch_normalization_8  (None, 56, 56, 128)      515       \n",
            "  (QuantizeWrapperV2)                                            \n",
            "                                                                 \n",
            " quant_max_pooling2d_8 (Quan  (None, 28, 28, 128)      1         \n",
            " tizeWrapperV2)                                                  \n",
            "                                                                 \n",
            " quant_conv2d_9 (QuantizeWra  (None, 28, 28, 192)      221761    \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            " quant_batch_normalization_9  (None, 28, 28, 192)      771       \n",
            "  (QuantizeWrapperV2)                                            \n",
            "                                                                 \n",
            " quant_max_pooling2d_9 (Quan  (None, 14, 14, 192)      1         \n",
            " tizeWrapperV2)                                                  \n",
            "                                                                 \n",
            " quant_conv2d_10 (QuantizeWr  (None, 14, 14, 64)       110785    \n",
            " apperV2)                                                        \n",
            "                                                                 \n",
            " quant_batch_normalization_1  (None, 14, 14, 64)       259       \n",
            " 0 (QuantizeWrapperV2)                                           \n",
            "                                                                 \n",
            " quant_max_pooling2d_10 (Qua  (None, 7, 7, 64)         1         \n",
            " ntizeWrapperV2)                                                 \n",
            "                                                                 \n",
            " quant_conv2d_11 (QuantizeWr  (None, 7, 7, 32)         18529     \n",
            " apperV2)                                                        \n",
            "                                                                 \n",
            " quant_batch_normalization_1  (None, 7, 7, 32)         131       \n",
            " 1 (QuantizeWrapperV2)                                           \n",
            "                                                                 \n",
            " quant_max_pooling2d_11 (Qua  (None, 3, 3, 32)         1         \n",
            " ntizeWrapperV2)                                                 \n",
            "                                                                 \n",
            " quant_flatten_1 (QuantizeWr  (None, 288)              1         \n",
            " apperV2)                                                        \n",
            "                                                                 \n",
            " quant_dropout_2 (QuantizeWr  (None, 288)              1         \n",
            " apperV2)                                                        \n",
            "                                                                 \n",
            " quant_dense_2 (QuantizeWrap  (None, 1000)             289005    \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            " quant_dropout_3 (QuantizeWr  (None, 1000)             1         \n",
            " apperV2)                                                        \n",
            "                                                                 \n",
            " quant_dense_3 (QuantizeWrap  (None, 10)               10015     \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 747,408\n",
            "Trainable params: 745,314\n",
            "Non-trainable params: 2,094\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "q_aware_model = quantize_model(model)\n",
        "q_aware_model.compile(optimizer = opt, loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "q_aware_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Prepare training dataset"
      ],
      "metadata": {
        "id": "SklURQTBeC_u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "ttJjDT4fxypo"
      },
      "outputs": [],
      "source": [
        "quantize_train, quant_train_info = tfds.load(DataSet, split='train + test[:75%]', with_info=True, as_supervised=True)\n",
        "filtered_quantize_train = quantize_train.filter(lambda x, y: filter_fn(y, class_list))\n",
        "\n",
        "resized_quantize_train = prepare(filtered_quantize_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Au1jzJfrBxNO",
        "outputId": "1ed7dc5e-6ef6-479d-e738-4fc375c127ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "23/23 [==============================] - 16s 620ms/step - loss: 9.2582 - accuracy: 0.8285\n",
            "Epoch 2/5\n",
            "23/23 [==============================] - 11s 474ms/step - loss: 9.0814 - accuracy: 0.8711\n",
            "Epoch 3/5\n",
            "23/23 [==============================] - 10s 432ms/step - loss: 8.9480 - accuracy: 0.8876\n",
            "Epoch 4/5\n",
            "23/23 [==============================] - 10s 426ms/step - loss: 8.8472 - accuracy: 0.9075\n",
            "Epoch 5/5\n",
            "23/23 [==============================] - 10s 428ms/step - loss: 8.7581 - accuracy: 0.9275\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6cf30b4400>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "resized_quantize_train = resized_quantize_train.batch(BATCH_SIZE)\n",
        "q_aware_model.fit(resized_quantize_train, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Convert into a tflite model (With Default conversion for weights and biases)"
      ],
      "metadata": {
        "id": "019TQVwGeH4m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQ5TWSxVzIIL",
        "outputId": "a6e27508-ff07-4e72-eee0-b51533a1fde9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_6_layer_call_fn, conv2d_6_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, conv2d_7_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses while saving (showing 5 of 28). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/lite/python/convert.py:766: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
          ]
        }
      ],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "quantized_tflite_model = converter.convert()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluation functions (Self defined)"
      ],
      "metadata": {
        "id": "UfF4m7A6eaOe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Quantized model accuracy"
      ],
      "metadata": {
        "id": "auVU4_OgeeWW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "m5FUhkwN3hQ_"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(interpreter, test):\n",
        "    test_labels = []\n",
        "\n",
        "\n",
        "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "    \n",
        "    # Run predictions on every image in the \"test\" dataset.\n",
        "    prediction_digits = []\n",
        "    for i, test_example in enumerate(test):\n",
        "        if i % 1000 == 0:\n",
        "            print('Evaluated on {n} results so far.'.format(n=i))\n",
        "        test_labels.append(test_example[-1])\n",
        "        test_image = test_example[0]\n",
        "        # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "        # the model's input data format.\n",
        "        #display(test_image.shape)\n",
        "        test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "        #test_image = np.expand_dims(test_image, axis=3).astype(np.float32)\n",
        "        #display(test_image.shape)\n",
        "        interpreter.set_tensor(input_index, test_image)\n",
        "        \n",
        "        # Run inference.\n",
        "        interpreter.invoke()\n",
        "        \n",
        "        # Post-processing: remove batch dimension and find the digit with highest\n",
        "        # probability.\n",
        "        output = interpreter.tensor(output_index)\n",
        "        digit = np.argmax(output()[0])\n",
        "        prediction_digits.append(digit)\n",
        "        \n",
        "    print('\\n')\n",
        "    # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "    prediction_digits = np.array(prediction_digits)\n",
        "    accuracy = (prediction_digits == test_labels).mean()\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Fj2J-4RRYvd",
        "outputId": "3d4a2da0-9e2f-4fd6-e7e2-32c69318caa8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluated on 0 results so far.\n",
            "Evaluated on 1000 results so far.\n",
            "Evaluated on 2000 results so far.\n",
            "Evaluated on 3000 results so far.\n",
            "Evaluated on 4000 results so far.\n",
            "Evaluated on 5000 results so far.\n",
            "Evaluated on 6000 results so far.\n",
            "\n",
            "\n",
            "Quant TFLite test_accuracy: 0.6599276791584484\n"
          ]
        }
      ],
      "source": [
        "#Models obtained from TfLiteConverter can be run in Python with Interpreter.\n",
        "interpreter = tf.lite.Interpreter(model_content=quantized_tflite_model)\n",
        "#Since TensorFlow Lite pre-plans tensor allocations to optimize inference, the user needs to call allocate_tensors() before any inference.\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "test_accuracy = evaluate_model(interpreter, test_as_np)\n",
        "\n",
        "print('Quant TFLite test_accuracy:', test_accuracy)\n",
        "#print('Quant TF test accuracy:', q_aware_model_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6k1Pdc-2xmX"
      },
      "source": [
        "#Save models to run on Hardware"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Float model"
      ],
      "metadata": {
        "id": "MXfJ6R2dfAd_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "cna44KG62VL3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56f5ca45-ee1a-4b0a-a1e7-bd473a6d3585"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "MODEL_DIR = \"CadenceNet_Float\"\n",
        "model.save(MODEL_DIR, save_format=\"tf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Za8NOpnC3P7p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54c645cf-15ad-4f04-e071-54e6ad8e6f53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tf2onnx\n",
            "  Downloading tf2onnx-1.13.0-py3-none-any.whl (442 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.3/442.3 KB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tf2onnx) (1.12)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from tf2onnx) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from tf2onnx) (2.25.1)\n",
            "Collecting onnx>=1.4.1\n",
            "  Downloading onnx-1.13.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.8/dist-packages (from tf2onnx) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.8/dist-packages (from onnx>=1.4.1->tf2onnx) (4.4.0)\n",
            "Collecting protobuf<4,>=3.20.2\n",
            "  Downloading protobuf-3.20.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->tf2onnx) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->tf2onnx) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->tf2onnx) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->tf2onnx) (4.0.0)\n",
            "Installing collected packages: protobuf, onnx, tf2onnx\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.19.6\n",
            "    Uninstalling protobuf-3.19.6:\n",
            "      Successfully uninstalled protobuf-3.19.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.9.2 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n",
            "tensorboard 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed onnx-1.13.0 protobuf-3.20.3 tf2onnx-1.13.0\n",
            "/usr/lib/python3.8/runpy.py:127: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "2023-01-28 12:45:12,126 - WARNING - '--tag' not specified for saved_model. Using --tag serve\n",
            "2023-01-28 12:45:13,164 - INFO - Signatures found in model: [serving_default].\n",
            "2023-01-28 12:45:13,164 - WARNING - '--signature_def' not specified, using first signature: serving_default\n",
            "2023-01-28 12:45:13,164 - INFO - Output names: ['dense_3']\n",
            "2023-01-28 12:45:13,410 - INFO - Using tensorflow=2.9.2, onnx=1.13.0, tf2onnx=1.13.0/2c1db5\n",
            "2023-01-28 12:45:13,410 - INFO - Using opset <onnx, 13>\n",
            "2023-01-28 12:45:13,582 - INFO - Computed 0 values for constant folding\n",
            "2023-01-28 12:45:13,727 - INFO - Optimizing ONNX model\n",
            "2023-01-28 12:45:13,831 - INFO - After optimization: BatchNormalization -6 (6->0), Cast -1 (1->0), Const -24 (41->17), Identity -2 (2->0), Transpose -34 (36->2)\n",
            "2023-01-28 12:45:13,836 - INFO - \n",
            "2023-01-28 12:45:13,836 - INFO - Successfully converted TensorFlow model /content/CadenceNet_Float/ to ONNX\n",
            "2023-01-28 12:45:13,836 - INFO - Model inputs: ['conv2d_6_input']\n",
            "2023-01-28 12:45:13,836 - INFO - Model outputs: ['dense_3']\n",
            "2023-01-28 12:45:13,836 - INFO - ONNX model is saved at /content/CadenceNet_Float_sparseCrossEntropy.onnx\n"
          ]
        }
      ],
      "source": [
        "#convert to onnx\n",
        "!pip install -U tf2onnx\n",
        "!python -m tf2onnx.convert --saved-model /content/CadenceNet_Float/ --output /content/CadenceNet_Float_sparseCrossEntropy.onnx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-KO0PW93dB3"
      },
      "source": [
        "#QAT model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "4N_Z-Yev3e4o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34f8a0b5-40a6-442b-d151-f4dd896cf1ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "770448"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "quant_file = \"/content/quantized_model_sparseCrossEntropy_Rescaled.tflite\"\n",
        "open(quant_file, \"wb\").write(quantized_tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(\"Float model in Mb:\", os.path.getsize(\"/content/CadenceNet_Float_sparseCrossEntropy.onnx\") / float(2**20))\n",
        "print(\"Quantized model in Mb:\", os.path.getsize(quant_file) / float(2**20))"
      ],
      "metadata": {
        "id": "PL_9KH5oLzV2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "175a2f22-9fd9-45b3-9d0a-92eea47d8ff4"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Float model in Mb: 2.8464298248291016\n",
            "Quantized model in Mb: 0.7347564697265625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice from above experiments that the FLoat model accuracy persist even after quantization.\n",
        "*   Float test_accuracy: 0.653517422748192\n",
        "*   Quant TFLite test_accuracy: 0.6599276791584484\n",
        "\n",
        "Meanwhile the Model size has decreased by a factor of approximately 4\n",
        "* Float model in Mb: 2.8464298248291016\n",
        "* Quantized model in Mb: 0.7347564697265625\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YVDyTUtGgv5f"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}