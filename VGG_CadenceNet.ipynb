{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PinakW/DIssertation_expt/blob/main/VGG_CadenceNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BCeppY1fBRsz"
      },
      "outputs": [],
      "source": [
        "USE_ORIGINAL = 0\n",
        "loss = 'categorical_crossentropy'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IYvbodAaO5NT"
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "#For plotting the dataset\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "#Data pipeline preparation\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "#model building\n",
        "from tensorflow.keras import models\n",
        "import tensorflow.keras.utils as tfutils\n",
        "import os\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bJSJfW_tPA88"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = 10\n",
        "\n",
        "DataSet = 'cifar10'\n",
        "#'caltech101'\n",
        "#'cifar10'\n",
        "def num_samples_per_class(ds_train, get_top_10 = False, print_all = False):\n",
        "    vals = np.unique(np.fromiter(ds_train.map(lambda x, y: y), int), return_counts=True)\n",
        "    class_list = []\n",
        "    class_hist = []\n",
        "    for val,count in zip(*vals):\n",
        "        if print_all==True:\n",
        "            print(int(val), count)\n",
        "        class_hist.append((val,count))\n",
        "    if get_top_10 == True:\n",
        "        sorted_tuple = sorted(class_hist, key=lambda t: t[-1], reverse=True)[:(NUM_CLASSES + 1)]    #+1 because we are going to remove \"backround_google\" i.e. 4\n",
        "        class_list = [x for x,y in sorted_tuple]\n",
        "    return class_list\n",
        "\n",
        "def filter_fn(x, allowed_classes:list):\n",
        "    allowed_classes = tf.constant(allowed_classes)\n",
        "    isallowed = tf.equal(allowed_classes, tf.cast(x, allowed_classes.dtype))\n",
        "    reduced_sum = tf.reduce_sum(tf.cast(isallowed, tf.float32))\n",
        "    return tf.greater(reduced_sum, tf.constant(0.))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2fLIbNS2PDZ1"
      },
      "outputs": [],
      "source": [
        "if DataSet == 'caltech101':\n",
        "    ds_train, train_info = tfds.load(DataSet, split='test[0:90%]', as_supervised=True, with_info = True)\n",
        "    ds_test = tfds.load(DataSet, split='train', as_supervised=True)\n",
        "    ds_val = tfds.load(DataSet, split='test[90%:]', as_supervised=True) \n",
        "else:\n",
        "    ds_train, train_info = tfds.load(DataSet, split='train[0:80%]', as_supervised=True, with_info = True)   #taking 0 to 80% for training\n",
        "    ds_test = tfds.load(DataSet, split='test', as_supervised=True)        \n",
        "    ds_val = tfds.load(DataSet, split='test[80%:]', as_supervised=True)                                     #taking data from 80% point to the end of the dataset (100%) for validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOoGq7JtPGn8",
        "outputId": "c26a3541-4392-4789-cbe8-2c6e6b905d82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        }
      ],
      "source": [
        "class_list = num_samples_per_class(ds_train, get_top_10=True)\n",
        "if DataSet == 'caltech101':\n",
        "  class_list = [i for i in class_list if i != train_info.features['label'].str2int('background_google')]\n",
        "  class_list.sort()\n",
        "class_names = [train_info.features['label'].int2str(i) for i in class_list]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VeThcLypHU4m"
      },
      "outputs": [],
      "source": [
        "resized_ds_train = ds_train.filter(lambda x, y: filter_fn(y, class_list)) # as_supervised\n",
        "resized_ds_test = ds_test.filter(lambda x, y: filter_fn(y, class_list))\n",
        "resized_ds_val = ds_val.filter(lambda x, y: filter_fn(y, class_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QdPKLGVdPNrk"
      },
      "outputs": [],
      "source": [
        "#Hyperparameters\n",
        "if DataSet=='caltech101':\n",
        "    IMG_SIZE = 60\n",
        "elif DataSet=='cifar10':\n",
        "    IMG_SIZE = 32\n",
        "NUM_CHANNELS = 3\n",
        "BATCH_SIZE=128\n",
        "\n",
        "input_shape = (IMG_SIZE,IMG_SIZE,NUM_CHANNELS)\n",
        "#Relabelling to avoid issues. Note that human readability is reduced by this\n",
        "table = tf.lookup.StaticHashTable(\n",
        "    initializer=tf.lookup.KeyValueTensorInitializer(\n",
        "        keys=tf.constant(class_list, dtype=tf.int64),\n",
        "        values=tf.constant([0, 1, 2, 3, 4, 5, 6, 7, 8, 9],  dtype=tf.int64)\n",
        "    ),\n",
        "    default_value= tf.constant(0,  dtype=tf.int64)\n",
        ")\n",
        "\n",
        "#This function will be used in the graph execution hence @tf.function prefix\n",
        "@tf.function\n",
        "def map_func(label):\n",
        "    global class_list\n",
        "    global loss\n",
        "    mapped_label = table.lookup(label)\n",
        "    if loss != 'sparse_categorical_crossentropy':\n",
        "        mapped_label = tf.one_hot(indices=mapped_label, depth=NUM_CLASSES)\n",
        "    print(\"Label = \" + str(label) + \"\\t\" + \"Mapped Label = \" + str(mapped_label))\n",
        "    return mapped_label\n",
        "\n",
        "#Preprocessing done as part of the graph\n",
        "resize_and_rescale = tf.keras.Sequential([\n",
        "  layers.Resizing(IMG_SIZE, IMG_SIZE),\n",
        "  layers.Rescaling(1./255)\n",
        "])\n",
        "\n",
        "resize_layer = tf.keras.Sequential([\n",
        "  layers.Resizing(IMG_SIZE, IMG_SIZE),\n",
        "])\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  layers.RandomRotation(0.2),\n",
        "])\n",
        "\n",
        "buffer_size = 30*NUM_CLASSES\n",
        "\n",
        "#Preprocessing function which invokes above graphs\n",
        "def prepare(ds, shuffle=False, augment=False, resize_only = False):\n",
        "    global buffer_size\n",
        "    global BATCH_SIZE\n",
        "    \n",
        "\n",
        "    # Resize and rescale all datasets.\n",
        "    if resize_only==True:\n",
        "        ds = ds.map(lambda x, y: (resize_layer(x), map_func(y)), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    else:\n",
        "        ds = ds.map(lambda x, y: (resize_and_rescale(x), map_func(y)), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    \n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size)\n",
        "        \n",
        "    # Batch all datasets.\n",
        "    #ds = ds.batch(BATCH_SIZE)\n",
        "\n",
        "    # Use data augmentation only on the training set.\n",
        "    if augment:\n",
        "        ds_aug = ds.map(lambda x, y: (data_augmentation(x, training=True), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "        ds = ds.concatenate(ds_aug)\n",
        "\n",
        "        \n",
        "    # Use buffered prefetching on all datasets.\n",
        "    return ds.prefetch(buffer_size=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmLFCHD6PgLw",
        "outputId": "3ba2ff24-869a-4586-9149-465ee7789687"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label = Tensor(\"label:0\", shape=(), dtype=int64)\tMapped Label = Tensor(\"one_hot:0\", shape=(10,), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "resized_ds_train = prepare(resized_ds_train, augment=True)\n",
        "resized_ds_test = prepare(resized_ds_test)\n",
        "resized_ds_val = prepare(resized_ds_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uf1KScmu9odE"
      },
      "outputs": [],
      "source": [
        "def num_samples_per_class_onehot(resized_ds_train, print_all=False):\n",
        "    if loss != 'sparse_categorical_crossentropy':\n",
        "        vals = np.unique(np.fromiter(resized_ds_train.map(lambda x, y: tf.argmax(y)), int), return_counts=True)\n",
        "    else:\n",
        "        vals = np.unique(np.fromiter(resized_ds_train.map(lambda x, y: y), int), return_counts=True)\n",
        "    class_list = []\n",
        "    class_hist = []\n",
        "    for val,count in zip(*vals):\n",
        "        if print_all==True:\n",
        "            print(int(val), count)\n",
        "        class_hist.append((val,count))\n",
        "    class_hist.sort()\n",
        "    return class_hist\n",
        "#Post prepare function, all the labels will be converted to one hot encoders. In order to get class-wise distribution, we will need to convert each one hot encoder into its label (temporarily)\n",
        "#We need a new function to handle it\n",
        "class_hist = num_samples_per_class_onehot(resized_ds_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ftnZ5OyvQB98",
        "outputId": "720616e6-0f95-4f24-9f6e-82b93592158d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Quantization scheme experiments'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#reg = tf.keras.regularizers.L2(0.01)\n",
        "reg = tf.keras.regularizers.L1L2(l1 =0.0, l2 = 0.1)\n",
        "#reg = tf.keras.regularizers.L1L2(l1 =0.0, l2 = 0.0)\n",
        "#beta_regularizer = 0.1\n",
        "#gamma_regularizer = 0.1\n",
        "\n",
        "model = models.Sequential()\n",
        "kernel_size = (3,3)\n",
        "pool_size = (2,2)\n",
        "if USE_ORIGINAL == 1:\n",
        "\tdisplay(\"Default quantization scheme\")\n",
        "\t\n",
        "\tmodel.add(layers.Conv2D(32, kernel_size, kernel_initializer='he_uniform', kernel_regularizer = reg, padding='same', input_shape=(IMG_SIZE, IMG_SIZE, NUM_CHANNELS)))\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.Conv2D(32, kernel_size, kernel_initializer='he_uniform', kernel_regularizer = reg, padding='same'))\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.MaxPooling2D(pool_size))\n",
        "\tmodel.add(layers.Dropout(0.1))\n",
        "\t\n",
        "\tmodel.add(layers.Conv2D(64, kernel_size, kernel_initializer='he_uniform', kernel_regularizer = reg, padding='same'))\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.Conv2D(64, kernel_size, kernel_initializer='he_uniform', kernel_regularizer = reg, padding='same'))\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.MaxPooling2D(pool_size))\n",
        "\tmodel.add(layers.Dropout(0.2))\n",
        "\t\n",
        "\tmodel.add(layers.Conv2D(128, kernel_size, kernel_initializer='he_uniform', kernel_regularizer = reg, padding='same'))\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.Conv2D(128, kernel_size, kernel_initializer='he_uniform', kernel_regularizer = reg, padding='same'))\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.MaxPooling2D(pool_size))\n",
        "\tmodel.add(layers.Dropout(0.3))\n",
        "\t\n",
        "\tmodel.add(layers.Flatten())\n",
        "\tmodel.add(layers.Dense(128, kernel_initializer='he_uniform', kernel_regularizer = reg))\n",
        "\tif 0:\n",
        "\t\t\"\"\"\n",
        "\t\tThe converter quantizes batchnorm iff it follows a Conv2D layer. Hence we remove this BatchNorm layer (although it helps in accuracy).\n",
        "\t\tSo we trade off accuracy for smaller model size\n",
        "\t\t\"\"\"\n",
        "\t\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.Dropout(0.2))\n",
        "\tmodel.add(layers.Dense(NUM_CLASSES, kernel_regularizer = reg))\n",
        "\tmodel.add(layers.Softmax())\n",
        "else:\n",
        "\tdisplay(\"Quantization scheme experiments\")\n",
        "\t\n",
        "\tmodel.add(layers.Conv2D(32, kernel_size, kernel_initializer='he_uniform', kernel_regularizer = reg, padding='same', input_shape=(IMG_SIZE, IMG_SIZE, NUM_CHANNELS)))\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.Conv2D(32, kernel_size, kernel_initializer='he_uniform', kernel_regularizer = reg, padding='same'))\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.MaxPooling2D(pool_size))\n",
        "\tmodel.add(layers.Dropout(0.1))\n",
        "\t\n",
        "\tmodel.add(layers.Conv2D(64, kernel_size, kernel_initializer='he_uniform', kernel_regularizer = reg, padding='same'))\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.Conv2D(64, kernel_size, kernel_initializer='he_uniform', kernel_regularizer = reg, padding='same'))\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.MaxPooling2D(pool_size))\n",
        "\tmodel.add(layers.Dropout(0.2))\n",
        "\t\n",
        "\tmodel.add(layers.Conv2D(128, kernel_size, kernel_initializer='he_uniform', kernel_regularizer = reg, padding='same'))\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.Conv2D(128, kernel_size, kernel_initializer='he_uniform', kernel_regularizer = reg, padding='same'))\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.MaxPooling2D(pool_size))\n",
        "\tmodel.add(layers.Dropout(0.3))\n",
        "\t\n",
        "\tmodel.add(layers.Flatten())\n",
        "\tmodel.add(layers.Dense(128, kernel_initializer='he_uniform', kernel_regularizer = reg))\n",
        "\tif 1:\n",
        "\t\t\"\"\"\n",
        "\t\tThe converter quantizes batchnorm iff it follows a Conv2D layer. Hence we remove this BatchNorm layer (although it helps in accuracy).\n",
        "\t\tSo we trade off accuracy for smaller model size\n",
        "\t\t\"\"\"\n",
        "\t\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.Dropout(0.2))\n",
        "\tmodel.add(layers.Dense(NUM_CLASSES, kernel_regularizer = reg))\n",
        "\tmodel.add(layers.Softmax())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "B-aANPwedhNH"
      },
      "outputs": [],
      "source": [
        "def get_class_weights(class_hist):\n",
        "    \"\"\"\n",
        "    Returns the class weights as a tf.Tensor. Class weights are inverse of the class frequencies\n",
        "    Class frequencies are the number of samples of each class which we calculate in earlier steps\n",
        "    \"\"\"\n",
        "    inv_freq = tf.convert_to_tensor([1.0/count for label, count in class_hist], dtype=tf.float32)\n",
        "    return tfutils.normalize(inv_freq)\n",
        "\n",
        "\n",
        "def weightedloss(y_true, y_pred, gamma, class_weight):\n",
        "    \"\"\"\n",
        "    We assume that all arguments coming into this function are tf.Tensors type\n",
        "    class_weights are basically alpha in focal loss paper\n",
        "    \"\"\"\n",
        "    #ones = tf.convert_to_tensor(np.ones(shape=len(y_true)))\n",
        "    a = tf.math.multiply(tf.math.pow(tf.math.subtract(1.0, y_pred), gamma), tf.math.log(y_pred))  #((1-pt)^gamma)log(pt)\n",
        "    b = tf.math.multiply(-1.0, class_weight)                                                          #-alpha\n",
        "    b = tf.math.multiply(b,a)    \n",
        "    b = tf.math.multiply(b, y_true)\n",
        "    return b\n",
        "class WeightedLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self, gamma, class_weight=np.ones(shape=NUM_CLASSES, dtype=np.float32)):\n",
        "        super().__init__()\n",
        "        self.gamma = tf.convert_to_tensor(gamma)\n",
        "        self.class_weight = tf.convert_to_tensor(class_weight, dtype=tf.float32)\n",
        "    def call(self, y_true, y_pred):\n",
        "        return weightedloss(y_true, y_pred, self.gamma, self.class_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fHRlWtV83IeV"
      },
      "outputs": [],
      "source": [
        "Learning_Rate = 1e-5\n",
        "\n",
        "#tf.keras.optimizers.Adam(learning_rate=Learning_Rate)     #OR tf.keras.optimizers.SGD(learning_rate=Learning_Rate, momentum=0.9)\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=Learning_Rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "DHFaNgqtwZGz"
      },
      "outputs": [],
      "source": [
        "###EITHER\n",
        "\n",
        "#!pip install focal-loss\n",
        "#from focal_loss import SparseCategoricalFocalLoss \n",
        "#model.compile( optimizer = opt, loss = SparseCategoricalFocalLoss(gamma=2), metrics=['accuracy'] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "nFFBTJNwLAcA"
      },
      "outputs": [],
      "source": [
        "###OR\n",
        "model.compile( optimizer = opt, loss = loss, metrics=['accuracy'] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "pmqZtduVbl-2"
      },
      "outputs": [],
      "source": [
        "###OR\n",
        "#class_wts = get_class_weights(class_hist)\n",
        "#display(class_wts)\n",
        "#model.compile( optimizer = opt, loss = WeightedLoss(gamma=2.0), metrics=['accuracy'] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "HL7YFZKvbn92"
      },
      "outputs": [],
      "source": [
        "#model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNi4QKkp27-d",
        "outputId": "1a460a1e-7b54-4129-d606-4d25eeeb4940"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "625/625 [==============================] - 43s 57ms/step - loss: 110.5841 - accuracy: 0.1419 - val_loss: 101.3618 - val_accuracy: 0.1990\n",
            "Epoch 2/80\n",
            "625/625 [==============================] - 33s 54ms/step - loss: 93.5708 - accuracy: 0.1979 - val_loss: 85.8006 - val_accuracy: 0.2630\n",
            "Epoch 3/80\n",
            "625/625 [==============================] - 34s 55ms/step - loss: 79.1822 - accuracy: 0.2456 - val_loss: 72.6060 - val_accuracy: 0.3005\n",
            "Epoch 4/80\n",
            "625/625 [==============================] - 34s 54ms/step - loss: 66.9767 - accuracy: 0.2860 - val_loss: 61.3929 - val_accuracy: 0.3365\n",
            "Epoch 5/80\n",
            "625/625 [==============================] - 33s 53ms/step - loss: 56.6171 - accuracy: 0.3184 - val_loss: 51.8848 - val_accuracy: 0.3640\n",
            "Epoch 6/80\n",
            "625/625 [==============================] - 33s 53ms/step - loss: 47.8493 - accuracy: 0.3461 - val_loss: 43.8341 - val_accuracy: 0.3950\n",
            "Epoch 7/80\n",
            "625/625 [==============================] - 33s 53ms/step - loss: 40.4528 - accuracy: 0.3710 - val_loss: 37.0736 - val_accuracy: 0.4090\n",
            "Epoch 8/80\n",
            "625/625 [==============================] - 35s 55ms/step - loss: 34.2509 - accuracy: 0.3894 - val_loss: 31.4207 - val_accuracy: 0.4270\n",
            "Epoch 9/80\n",
            "625/625 [==============================] - 34s 54ms/step - loss: 29.0783 - accuracy: 0.4081 - val_loss: 26.7272 - val_accuracy: 0.4335\n",
            "Epoch 10/80\n",
            "625/625 [==============================] - 33s 53ms/step - loss: 24.7871 - accuracy: 0.4287 - val_loss: 22.8628 - val_accuracy: 0.4350\n",
            "Epoch 11/80\n",
            "625/625 [==============================] - 33s 53ms/step - loss: 21.2515 - accuracy: 0.4449 - val_loss: 19.7125 - val_accuracy: 0.4295\n",
            "Epoch 12/80\n",
            "625/625 [==============================] - 35s 56ms/step - loss: 18.3539 - accuracy: 0.4586 - val_loss: 17.1074 - val_accuracy: 0.4445\n",
            "Epoch 13/80\n",
            "625/625 [==============================] - 36s 58ms/step - loss: 15.9810 - accuracy: 0.4754 - val_loss: 15.0121 - val_accuracy: 0.4420\n",
            "Epoch 14/80\n",
            "625/625 [==============================] - 36s 57ms/step - loss: 14.0447 - accuracy: 0.4885 - val_loss: 13.2603 - val_accuracy: 0.4685\n",
            "Epoch 15/80\n",
            "625/625 [==============================] - 35s 55ms/step - loss: 12.4609 - accuracy: 0.5034 - val_loss: 11.8565 - val_accuracy: 0.4725\n",
            "Epoch 16/80\n",
            "625/625 [==============================] - 35s 56ms/step - loss: 11.1614 - accuracy: 0.5165 - val_loss: 10.7057 - val_accuracy: 0.4750\n",
            "Epoch 17/80\n",
            "625/625 [==============================] - 35s 56ms/step - loss: 10.0928 - accuracy: 0.5305 - val_loss: 9.7148 - val_accuracy: 0.4900\n",
            "Epoch 18/80\n",
            "625/625 [==============================] - 34s 55ms/step - loss: 9.2044 - accuracy: 0.5435 - val_loss: 8.9078 - val_accuracy: 0.5015\n",
            "Epoch 19/80\n",
            "625/625 [==============================] - 35s 56ms/step - loss: 8.4578 - accuracy: 0.5551 - val_loss: 8.1863 - val_accuracy: 0.5245\n",
            "Epoch 20/80\n",
            "625/625 [==============================] - 34s 55ms/step - loss: 7.8228 - accuracy: 0.5706 - val_loss: 7.6304 - val_accuracy: 0.5300\n",
            "Epoch 21/80\n",
            "625/625 [==============================] - 36s 57ms/step - loss: 7.2808 - accuracy: 0.5801 - val_loss: 7.1075 - val_accuracy: 0.5355\n",
            "Epoch 22/80\n",
            "625/625 [==============================] - 35s 56ms/step - loss: 6.8086 - accuracy: 0.5910 - val_loss: 6.6517 - val_accuracy: 0.5500\n",
            "Epoch 23/80\n",
            "625/625 [==============================] - 34s 54ms/step - loss: 6.3955 - accuracy: 0.6017 - val_loss: 6.2753 - val_accuracy: 0.5540\n",
            "Epoch 24/80\n",
            "625/625 [==============================] - 35s 56ms/step - loss: 6.0259 - accuracy: 0.6112 - val_loss: 5.9153 - val_accuracy: 0.5660\n",
            "Epoch 25/80\n",
            "625/625 [==============================] - 36s 58ms/step - loss: 5.6968 - accuracy: 0.6228 - val_loss: 5.5850 - val_accuracy: 0.5785\n",
            "Epoch 26/80\n",
            "625/625 [==============================] - 36s 57ms/step - loss: 5.4023 - accuracy: 0.6309 - val_loss: 5.2876 - val_accuracy: 0.5995\n",
            "Epoch 27/80\n",
            "625/625 [==============================] - 34s 55ms/step - loss: 5.1364 - accuracy: 0.6367 - val_loss: 5.0276 - val_accuracy: 0.6075\n",
            "Epoch 28/80\n",
            "625/625 [==============================] - 35s 56ms/step - loss: 4.8920 - accuracy: 0.6469 - val_loss: 4.8134 - val_accuracy: 0.6070\n",
            "Epoch 29/80\n",
            "625/625 [==============================] - 36s 57ms/step - loss: 4.6712 - accuracy: 0.6517 - val_loss: 4.6206 - val_accuracy: 0.5990\n",
            "Epoch 30/80\n",
            "625/625 [==============================] - 36s 58ms/step - loss: 4.4685 - accuracy: 0.6572 - val_loss: 4.3847 - val_accuracy: 0.6255\n",
            "Epoch 31/80\n",
            "625/625 [==============================] - 35s 56ms/step - loss: 4.2792 - accuracy: 0.6648 - val_loss: 4.1956 - val_accuracy: 0.6340\n",
            "Epoch 32/80\n",
            "625/625 [==============================] - 34s 55ms/step - loss: 4.1055 - accuracy: 0.6712 - val_loss: 4.0276 - val_accuracy: 0.6405\n",
            "Epoch 33/80\n",
            "625/625 [==============================] - 35s 56ms/step - loss: 3.9454 - accuracy: 0.6761 - val_loss: 3.8725 - val_accuracy: 0.6425\n",
            "Epoch 34/80\n",
            "625/625 [==============================] - 36s 58ms/step - loss: 3.7946 - accuracy: 0.6820 - val_loss: 3.7727 - val_accuracy: 0.6340\n",
            "Epoch 35/80\n",
            "625/625 [==============================] - 33s 54ms/step - loss: 3.6561 - accuracy: 0.6862 - val_loss: 3.6322 - val_accuracy: 0.6400\n",
            "Epoch 36/80\n",
            "625/625 [==============================] - 34s 54ms/step - loss: 3.5245 - accuracy: 0.6926 - val_loss: 3.4859 - val_accuracy: 0.6600\n",
            "Epoch 37/80\n",
            "625/625 [==============================] - 33s 53ms/step - loss: 3.4027 - accuracy: 0.6965 - val_loss: 3.3842 - val_accuracy: 0.6620\n",
            "Epoch 38/80\n",
            "625/625 [==============================] - 35s 55ms/step - loss: 3.2857 - accuracy: 0.7035 - val_loss: 3.2215 - val_accuracy: 0.6845\n",
            "Epoch 39/80\n",
            "625/625 [==============================] - 34s 54ms/step - loss: 3.1780 - accuracy: 0.7075 - val_loss: 3.1575 - val_accuracy: 0.6740\n",
            "Epoch 40/80\n",
            "625/625 [==============================] - 33s 53ms/step - loss: 3.0789 - accuracy: 0.7100 - val_loss: 3.0260 - val_accuracy: 0.6910\n",
            "Epoch 41/80\n",
            "625/625 [==============================] - 33s 53ms/step - loss: 2.9851 - accuracy: 0.7153 - val_loss: 2.9874 - val_accuracy: 0.6645\n",
            "Epoch 42/80\n",
            "625/625 [==============================] - 34s 55ms/step - loss: 2.8952 - accuracy: 0.7199 - val_loss: 2.9100 - val_accuracy: 0.6670\n",
            "Epoch 43/80\n",
            "625/625 [==============================] - 33s 53ms/step - loss: 2.8108 - accuracy: 0.7226 - val_loss: 2.7799 - val_accuracy: 0.6990\n",
            "Epoch 44/80\n",
            "625/625 [==============================] - 33s 53ms/step - loss: 2.7334 - accuracy: 0.7244 - val_loss: 2.7125 - val_accuracy: 0.7030\n",
            "Epoch 45/80\n",
            "625/625 [==============================] - 33s 53ms/step - loss: 2.6578 - accuracy: 0.7301 - val_loss: 2.6363 - val_accuracy: 0.7020\n",
            "Epoch 46/80\n",
            "625/625 [==============================] - 34s 55ms/step - loss: 2.5854 - accuracy: 0.7338 - val_loss: 2.5327 - val_accuracy: 0.7240\n",
            "Epoch 47/80\n",
            "625/625 [==============================] - 34s 55ms/step - loss: 2.5175 - accuracy: 0.7384 - val_loss: 2.4957 - val_accuracy: 0.7155\n",
            "Epoch 48/80\n",
            "625/625 [==============================] - 34s 55ms/step - loss: 2.4606 - accuracy: 0.7381 - val_loss: 2.4433 - val_accuracy: 0.7130\n",
            "Epoch 49/80\n",
            "625/625 [==============================] - 34s 54ms/step - loss: 2.4029 - accuracy: 0.7402 - val_loss: 2.3937 - val_accuracy: 0.7180\n",
            "Epoch 50/80\n",
            "625/625 [==============================] - 34s 54ms/step - loss: 2.3439 - accuracy: 0.7445 - val_loss: 2.2970 - val_accuracy: 0.7290\n",
            "Epoch 51/80\n",
            "625/625 [==============================] - 34s 54ms/step - loss: 2.2912 - accuracy: 0.7463 - val_loss: 2.2618 - val_accuracy: 0.7260\n",
            "Epoch 52/80\n",
            "625/625 [==============================] - 34s 54ms/step - loss: 2.2387 - accuracy: 0.7506 - val_loss: 2.2291 - val_accuracy: 0.7230\n",
            "Epoch 53/80\n",
            "625/625 [==============================] - 34s 54ms/step - loss: 2.1905 - accuracy: 0.7530 - val_loss: 2.1929 - val_accuracy: 0.7205\n",
            "Epoch 54/80\n",
            "625/625 [==============================] - 34s 54ms/step - loss: 2.1455 - accuracy: 0.7556 - val_loss: 2.1151 - val_accuracy: 0.7320\n",
            "Epoch 55/80\n",
            "625/625 [==============================] - 34s 54ms/step - loss: 2.0997 - accuracy: 0.7582 - val_loss: 2.1166 - val_accuracy: 0.7220\n",
            "Epoch 56/80\n",
            "625/625 [==============================] - 34s 55ms/step - loss: 2.0578 - accuracy: 0.7600 - val_loss: 2.0192 - val_accuracy: 0.7440\n",
            "Epoch 57/80\n",
            "625/625 [==============================] - 34s 54ms/step - loss: 2.0200 - accuracy: 0.7624 - val_loss: 2.0153 - val_accuracy: 0.7375\n",
            "Epoch 58/80\n",
            "625/625 [==============================] - 33s 53ms/step - loss: 1.9803 - accuracy: 0.7662 - val_loss: 1.9821 - val_accuracy: 0.7365\n",
            "Epoch 59/80\n",
            "625/625 [==============================] - 35s 56ms/step - loss: 1.9453 - accuracy: 0.7680 - val_loss: 1.9382 - val_accuracy: 0.7405\n",
            "Epoch 60/80\n",
            "625/625 [==============================] - 34s 54ms/step - loss: 1.9130 - accuracy: 0.7695 - val_loss: 1.8860 - val_accuracy: 0.7530\n",
            "Epoch 61/80\n",
            "625/625 [==============================] - 34s 55ms/step - loss: 1.8821 - accuracy: 0.7703 - val_loss: 1.9021 - val_accuracy: 0.7345\n",
            "Epoch 62/80\n",
            "625/625 [==============================] - 34s 55ms/step - loss: 1.8501 - accuracy: 0.7721 - val_loss: 1.8328 - val_accuracy: 0.7490\n",
            "Epoch 63/80\n",
            "625/625 [==============================] - 36s 57ms/step - loss: 1.8190 - accuracy: 0.7762 - val_loss: 1.8304 - val_accuracy: 0.7410\n",
            "Epoch 64/80\n",
            "625/625 [==============================] - 34s 54ms/step - loss: 1.7915 - accuracy: 0.7756 - val_loss: 1.8091 - val_accuracy: 0.7455\n",
            "Epoch 65/80\n",
            "625/625 [==============================] - 34s 54ms/step - loss: 1.7651 - accuracy: 0.7791 - val_loss: 1.7708 - val_accuracy: 0.7500\n",
            "Epoch 66/80\n",
            "625/625 [==============================] - 33s 53ms/step - loss: 1.7391 - accuracy: 0.7802 - val_loss: 1.7422 - val_accuracy: 0.7535\n",
            "Epoch 67/80\n",
            "625/625 [==============================] - 35s 56ms/step - loss: 1.7126 - accuracy: 0.7811 - val_loss: 1.7555 - val_accuracy: 0.7395\n",
            "Epoch 68/80\n",
            "625/625 [==============================] - 34s 54ms/step - loss: 1.6887 - accuracy: 0.7829 - val_loss: 1.6623 - val_accuracy: 0.7655\n",
            "Epoch 69/80\n",
            "625/625 [==============================] - 33s 52ms/step - loss: 1.6656 - accuracy: 0.7851 - val_loss: 1.6779 - val_accuracy: 0.7540\n",
            "Epoch 70/80\n",
            "625/625 [==============================] - 33s 53ms/step - loss: 1.6413 - accuracy: 0.7882 - val_loss: 1.6503 - val_accuracy: 0.7555\n",
            "Epoch 71/80\n",
            "625/625 [==============================] - 34s 54ms/step - loss: 1.6200 - accuracy: 0.7883 - val_loss: 1.6431 - val_accuracy: 0.7565\n",
            "Epoch 72/80\n",
            "625/625 [==============================] - 34s 54ms/step - loss: 1.5988 - accuracy: 0.7917 - val_loss: 1.5889 - val_accuracy: 0.7780\n",
            "Epoch 73/80\n",
            "625/625 [==============================] - 34s 54ms/step - loss: 1.5775 - accuracy: 0.7923 - val_loss: 1.5773 - val_accuracy: 0.7695\n",
            "Epoch 74/80\n",
            "625/625 [==============================] - 34s 54ms/step - loss: 1.5632 - accuracy: 0.7911 - val_loss: 1.5639 - val_accuracy: 0.7715\n",
            "Epoch 75/80\n",
            "625/625 [==============================] - 34s 54ms/step - loss: 1.5401 - accuracy: 0.7946 - val_loss: 1.5413 - val_accuracy: 0.7745\n",
            "Epoch 76/80\n",
            "625/625 [==============================] - 35s 56ms/step - loss: 1.5253 - accuracy: 0.7955 - val_loss: 1.5235 - val_accuracy: 0.7745\n",
            "Epoch 77/80\n",
            "625/625 [==============================] - 33s 53ms/step - loss: 1.5056 - accuracy: 0.7974 - val_loss: 1.5308 - val_accuracy: 0.7720\n",
            "Epoch 78/80\n",
            "625/625 [==============================] - 34s 54ms/step - loss: 1.4920 - accuracy: 0.7980 - val_loss: 1.5146 - val_accuracy: 0.7740\n",
            "Epoch 79/80\n",
            "625/625 [==============================] - 33s 53ms/step - loss: 1.4739 - accuracy: 0.8000 - val_loss: 1.5238 - val_accuracy: 0.7555\n",
            "Epoch 80/80\n",
            "625/625 [==============================] - 35s 56ms/step - loss: 1.4546 - accuracy: 0.8025 - val_loss: 1.4430 - val_accuracy: 0.7845\n"
          ]
        }
      ],
      "source": [
        "resized_ds_train = resized_ds_train.batch(BATCH_SIZE)\n",
        "resized_ds_val = resized_ds_val.batch(BATCH_SIZE)\n",
        "\n",
        "h = model.fit( resized_ds_train, epochs=80, validation_data = resized_ds_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "FuOyiBsTQkYL",
        "outputId": "61526341-9af6-4eec-9259-bea452ff558b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(h.history['loss'])\n",
        "plt.plot(h.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "5eodErTxg9BJ",
        "outputId": "e293064b-b49b-4392-ee12-8b357a05223f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(h.history['accuracy'])\n",
        "plt.plot(h.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "pxSSK5SPhnKL"
      },
      "outputs": [],
      "source": [
        "#Evaluation and confusion matrix creation:\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "x_test = np.asarray(list(map(lambda x: x[0], tfds.as_numpy(resized_ds_test))))\n",
        "y_test_orig = np.asarray(list(map(lambda x: x[1], tfds.as_numpy(resized_ds_test))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Tg4EdPBuc7fW",
        "outputId": "b5092cc3-0833-453f-f687-77546399e4cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step\n"
          ]
        }
      ],
      "source": [
        "predictions = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "sYYhORws1NnZ",
        "outputId": "cca73f16-1b9f-48e4-bf81-f306ad1eeb35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "if loss!='sparse_categorical_crossentropy':\n",
        "    false_arr = np.full(shape=len(class_list), fill_value = False)\n",
        "    #y_pred = np.empty(shape=y_test_orig.shape[-1])\n",
        "    i=0\n",
        "    for i, pred in enumerate(predictions):\n",
        "        temp_arr = copy.deepcopy(false_arr)\n",
        "        np.put(temp_arr, np.argmax(pred), True)\n",
        "        if i==0:\n",
        "            y_pred = copy.deepcopy(temp_arr)\n",
        "        else:\n",
        "            y_pred = np.vstack([y_pred, temp_arr])\n",
        "    display(y_pred.shape)\n",
        "else:\n",
        "    y_pred = np.argmax(predictions, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "o-iQ19WTaE9s",
        "outputId": "e57ce6ef-10b0-4ebf-efde-19d05e30ced1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(y_test_orig.shape)\n",
        "display(y_pred.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "phcwIL8RJQNQ",
        "outputId": "a61da759-035b-480e-8e76-518d7c03e4f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[884,  18,   3,   2,   4,  10,   8,   1,  30,  40],\n",
              "       [ 15, 868,  42,  10,  10,  36,   1,  11,   4,   3],\n",
              "       [  5,  28, 912,   2,   8,  11,   0,  15,   4,  15],\n",
              "       [ 19,  70,  53, 704,   6,  41,   3,  79,   7,  18],\n",
              "       [ 98, 140,  86,  53, 514,  42,  11,  26,   9,  21],\n",
              "       [ 19,  56,  13,  30,   6, 843,   1,  12,   3,  17],\n",
              "       [ 15,   2,   8,   2,   0,   1, 810,   1,  10, 151],\n",
              "       [ 24,  95, 121, 122,  15,  28,   3, 538,  19,  35],\n",
              "       [ 78,   6,   8,   1,   0,   2,   7,   1, 852,  45],\n",
              "       [ 25,   4,  15,   0,   1,   4,  15,   4,  10, 922]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    airplane       0.75      0.88      0.81      1000\n",
            "        deer       0.67      0.87      0.76      1000\n",
            "        frog       0.72      0.91      0.81      1000\n",
            "         dog       0.76      0.70      0.73      1000\n",
            "        bird       0.91      0.51      0.66      1000\n",
            "       horse       0.83      0.84      0.84      1000\n",
            "  automobile       0.94      0.81      0.87      1000\n",
            "         cat       0.78      0.54      0.64      1000\n",
            "        ship       0.90      0.85      0.87      1000\n",
            "       truck       0.73      0.92      0.81      1000\n",
            "\n",
            "   micro avg       0.78      0.78      0.78     10000\n",
            "   macro avg       0.80      0.78      0.78     10000\n",
            "weighted avg       0.80      0.78      0.78     10000\n",
            " samples avg       0.78      0.78      0.78     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('Confusion Matrix')\n",
        "if loss != 'sparse_categorical_crossentropy':\n",
        "    matrix = confusion_matrix(y_test_orig.argmax(axis=1), y_pred.argmax(axis=1))\n",
        "else:\n",
        "    matrix = confusion_matrix(y_test_orig, y_pred)\n",
        "display(matrix)\n",
        "\n",
        "# Print Classification Report\n",
        "print('Classification Report')\n",
        "print(classification_report(y_test_orig, y_pred, target_names=class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "7NaFdDuTQoyT"
      },
      "outputs": [],
      "source": [
        "def ret_as_numpy():\n",
        "    #test = tfds.load(DataSet, split='test', as_supervised=True)\n",
        "    #test = prepare(test)\n",
        "    #test = tfds.as_numpy(test)\n",
        "    return tfds.as_numpy(resized_ds_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Si_MguzMQuZL"
      },
      "outputs": [],
      "source": [
        "test_as_np = ret_as_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "xWYWlODgQrFy"
      },
      "outputs": [],
      "source": [
        "def evaluate_float_model(model, test):\n",
        "    test_labels = []\n",
        "    \n",
        "    # Run predictions on every image in the \"test\" dataset.\n",
        "    prediction_digits = []\n",
        "    for i, test_example in enumerate(test):\n",
        "        test_labels.append(np.argmax(test_example[-1]))\n",
        "        test_image = test_example[0]\n",
        "        # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "        # the model's input data format.\n",
        "        #display(test_image.shape)\n",
        "        test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "        \n",
        "        # Run inference.\n",
        "        output = model(test_image, training=False)\n",
        "        # Post-processing: remove batch dimension and find the digit with highest\n",
        "        # probability.\n",
        "        output = output.numpy()\n",
        "        digit = np.argmax(output[0])\n",
        "        prediction_digits.append(digit)\n",
        "        \n",
        "    print('\\n')\n",
        "    # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "    prediction_digits = np.array(prediction_digits)\n",
        "    accuracy = (prediction_digits == test_labels).mean()\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "BOHIU_J3QxE7",
        "outputId": "14676dc1-d0ab-4021-8e24-ba454b43cdba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Float test_accuracy: 0.7847\n"
          ]
        }
      ],
      "source": [
        "test_accuracy_Float = evaluate_float_model(model, test_as_np)\n",
        "\n",
        "print('Float test_accuracy:', test_accuracy_Float)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_Q2Is9IY-Oo"
      },
      "source": [
        "Float checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "5i9kUxj-4wNG",
        "outputId": "fce3e6fb-77b5-4643-ec3d-0a73857961ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/238.9 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.9/238.9 KB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "! pip install -q tensorflow-model-optimization\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "#To make the whole model aware of quantization,\n",
        "quantize_model = tfmot.quantization.keras.quantize_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "yWycqRCE4yBu",
        "outputId": "2026aa61-5c80-42fe-dd0d-9e23c04a7d8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " quantize_layer (QuantizeLay  (None, 32, 32, 3)        3         \n",
            " er)                                                             \n",
            "                                                                 \n",
            " quant_conv2d (QuantizeWrapp  (None, 32, 32, 32)       961       \n",
            " erV2)                                                           \n",
            "                                                                 \n",
            " quant_batch_normalization (  (None, 32, 32, 32)       129       \n",
            " QuantizeWrapperV2)                                              \n",
            "                                                                 \n",
            " quant_re_lu (QuantizeWrappe  (None, 32, 32, 32)       3         \n",
            " rV2)                                                            \n",
            "                                                                 \n",
            " quant_conv2d_1 (QuantizeWra  (None, 32, 32, 32)       9313      \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            " quant_batch_normalization_1  (None, 32, 32, 32)       129       \n",
            "  (QuantizeWrapperV2)                                            \n",
            "                                                                 \n",
            " quant_re_lu_1 (QuantizeWrap  (None, 32, 32, 32)       3         \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            " quant_max_pooling2d (Quanti  (None, 16, 16, 32)       1         \n",
            " zeWrapperV2)                                                    \n",
            "                                                                 \n",
            " quant_dropout (QuantizeWrap  (None, 16, 16, 32)       1         \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            " quant_conv2d_2 (QuantizeWra  (None, 16, 16, 64)       18625     \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            " quant_batch_normalization_2  (None, 16, 16, 64)       257       \n",
            "  (QuantizeWrapperV2)                                            \n",
            "                                                                 \n",
            " quant_re_lu_2 (QuantizeWrap  (None, 16, 16, 64)       3         \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            " quant_conv2d_3 (QuantizeWra  (None, 16, 16, 64)       37057     \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            " quant_batch_normalization_3  (None, 16, 16, 64)       257       \n",
            "  (QuantizeWrapperV2)                                            \n",
            "                                                                 \n",
            " quant_re_lu_3 (QuantizeWrap  (None, 16, 16, 64)       3         \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            " quant_max_pooling2d_1 (Quan  (None, 8, 8, 64)         1         \n",
            " tizeWrapperV2)                                                  \n",
            "                                                                 \n",
            " quant_dropout_1 (QuantizeWr  (None, 8, 8, 64)         1         \n",
            " apperV2)                                                        \n",
            "                                                                 \n",
            " quant_conv2d_4 (QuantizeWra  (None, 8, 8, 128)        74113     \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            " quant_batch_normalization_4  (None, 8, 8, 128)        513       \n",
            "  (QuantizeWrapperV2)                                            \n",
            "                                                                 \n",
            " quant_re_lu_4 (QuantizeWrap  (None, 8, 8, 128)        3         \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            " quant_conv2d_5 (QuantizeWra  (None, 8, 8, 128)        147841    \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            " quant_batch_normalization_5  (None, 8, 8, 128)        513       \n",
            "  (QuantizeWrapperV2)                                            \n",
            "                                                                 \n",
            " quant_re_lu_5 (QuantizeWrap  (None, 8, 8, 128)        3         \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            " quant_max_pooling2d_2 (Quan  (None, 4, 4, 128)        1         \n",
            " tizeWrapperV2)                                                  \n",
            "                                                                 \n",
            " quant_dropout_2 (QuantizeWr  (None, 4, 4, 128)        1         \n",
            " apperV2)                                                        \n",
            "                                                                 \n",
            " quant_flatten (QuantizeWrap  (None, 2048)             1         \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            " quant_dense (QuantizeWrappe  (None, 128)              262275    \n",
            " rV2)                                                            \n",
            "                                                                 \n",
            " quant_batch_normalization_6  (None, 128)              515       \n",
            "  (QuantizeWrapperV2)                                            \n",
            "                                                                 \n",
            " quant_re_lu_6 (QuantizeWrap  (None, 128)              3         \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            " quant_dropout_3 (QuantizeWr  (None, 128)              1         \n",
            " apperV2)                                                        \n",
            "                                                                 \n",
            " quant_dense_1 (QuantizeWrap  (None, 10)               1295      \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            " quant_softmax (QuantizeWrap  (None, 10)               1         \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 553,826\n",
            "Trainable params: 551,722\n",
            "Non-trainable params: 2,104\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "q_aware_model = quantize_model(model)\n",
        "#TODO: Check why this is not possible with Adam\n",
        "opt = tf.keras.optimizers.SGD(learning_rate=Learning_Rate, momentum=0.9)\n",
        "q_aware_model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
        "q_aware_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "blO0aYaP44O8",
        "outputId": "729eaaaa-ee94-420e-81a1-4c88b551a98c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "625/625 [==============================] - 43s 63ms/step - loss: 1.4332 - accuracy: 0.8056 - val_loss: 1.4459 - val_accuracy: 0.7765\n",
            "Epoch 2/5\n",
            "625/625 [==============================] - 40s 63ms/step - loss: 1.4176 - accuracy: 0.8062 - val_loss: 1.4136 - val_accuracy: 0.7790\n",
            "Epoch 3/5\n",
            "625/625 [==============================] - 40s 64ms/step - loss: 1.4003 - accuracy: 0.8091 - val_loss: 1.3883 - val_accuracy: 0.7870\n",
            "Epoch 4/5\n",
            "625/625 [==============================] - 39s 62ms/step - loss: 1.3859 - accuracy: 0.8103 - val_loss: 1.3633 - val_accuracy: 0.7995\n",
            "Epoch 5/5\n",
            "625/625 [==============================] - 40s 64ms/step - loss: 1.3665 - accuracy: 0.8131 - val_loss: 1.3346 - val_accuracy: 0.8000\n"
          ]
        }
      ],
      "source": [
        "h = q_aware_model.fit(resized_ds_train, epochs=5, validation_data = resized_ds_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "WButHzSy5BTH",
        "outputId": "9ea8aee7-f656-4153-dd96-dc3d3886024b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(h.history['loss'])\n",
        "plt.plot(h.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "GbugbXtI5Ecm",
        "outputId": "d009ae43-83ba-4012-f442-1ca97565bc01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses while saving (showing 5 of 48). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/lite/python/convert.py:765: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
          ]
        }
      ],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "quantized_tflite_model = converter.convert()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "iXBCHsjF5JiG"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(interpreter, test):\n",
        "    test_labels = []\n",
        "\n",
        "\n",
        "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "    \n",
        "    # Run predictions on every image in the \"test\" dataset.\n",
        "    prediction_digits = []\n",
        "    for i, test_example in enumerate(test):\n",
        "        test_labels.append(np.argmax(test_example[-1]))\n",
        "        test_image = test_example[0]\n",
        "        # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "        # the model's input data format.\n",
        "        test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "        interpreter.set_tensor(input_index, test_image)\n",
        "        \n",
        "        # Run inference.\n",
        "        interpreter.invoke()\n",
        "        \n",
        "        # Post-processing: remove batch dimension and find the digit with highest\n",
        "        # probability.\n",
        "        output = interpreter.tensor(output_index)\n",
        "        digit = np.argmax(output()[0])\n",
        "        prediction_digits.append(digit)\n",
        "        \n",
        "    print('\\n')\n",
        "    # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "    prediction_digits = np.array(prediction_digits)\n",
        "    accuracy = (prediction_digits == test_labels).mean()\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "rWyXRobN5NU_",
        "outputId": "f3e29aef-f6fb-47ee-b999-74d880d0cf7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Quant TFLite test_accuracy: 0.8038\n"
          ]
        }
      ],
      "source": [
        "#Models obtained from TfLiteConverter can be run in Python with Interpreter.\n",
        "interpreter = tf.lite.Interpreter(model_content=quantized_tflite_model)\n",
        "#Since TensorFlow Lite pre-plans tensor allocations to optimize inference, the user needs to call allocate_tensors() before any inference.\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "test_accuracy = evaluate_model(interpreter, test_as_np)\n",
        "\n",
        "print('Quant TFLite test_accuracy:', test_accuracy)\n",
        "#print('Quant TF test accuracy:', q_aware_model_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "KxEHJlru5PlG",
        "outputId": "a73b2e64-0d21-4ff1-c851-dd40fca7e1a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "MODEL_DIR = \"CadenceNet_Float\"\n",
        "model.save(MODEL_DIR, save_format=\"tf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "VHzmQxaT5R3W",
        "outputId": "bd5dc29f-4946-4013-9992-5d4092c8138c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tf2onnx==1.8.4\n",
            "  Downloading tf2onnx-1.8.4-py3-none-any.whl (345 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.3/345.3 KB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.8/dist-packages (from tf2onnx==1.8.4) (1.22.4)\n",
            "Collecting onnx>=1.4.1\n",
            "  Downloading onnx-1.13.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m94.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from tf2onnx==1.8.4) (1.15.0)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.8/dist-packages (from tf2onnx==1.8.4) (23.1.21)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from tf2onnx==1.8.4) (2.25.1)\n",
            "Collecting protobuf<4,>=3.20.2\n",
            "  Downloading protobuf-3.20.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.8/dist-packages (from onnx>=1.4.1->tf2onnx==1.8.4) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->tf2onnx==1.8.4) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->tf2onnx==1.8.4) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->tf2onnx==1.8.4) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->tf2onnx==1.8.4) (2.10)\n",
            "Installing collected packages: protobuf, onnx, tf2onnx\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.19.6\n",
            "    Uninstalling protobuf-3.19.6:\n",
            "      Successfully uninstalled protobuf-3.19.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed onnx-1.13.1 protobuf-3.20.3 tf2onnx-1.8.4\n",
            "2023-03-05 07:53:22.733154: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-05 07:53:22.733256: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-05 07:53:22.733274: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "/usr/lib/python3.8/runpy.py:127: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "2023-03-05 07:53:24,965 - WARNING - '--tag' not specified for saved_model. Using --tag serve\n",
            "2023-03-05 07:53:26,089 - INFO - Signatures found in model: [serving_default].\n",
            "2023-03-05 07:53:26,089 - WARNING - '--signature_def' not specified, using first signature: serving_default\n",
            "2023-03-05 07:53:26,089 - INFO - Output names: ['softmax']\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tf2onnx/tf_loader.py:557: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n",
            "2023-03-05 07:53:26,319 - WARNING - From /usr/local/lib/python3.8/dist-packages/tf2onnx/tf_loader.py:557: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n",
            "2023-03-05 07:53:26,378 - INFO - Using tensorflow=2.11.0, onnx=1.13.1, tf2onnx=1.8.4/cd55bf\n",
            "2023-03-05 07:53:26,379 - INFO - Using opset <onnx, 9>\n",
            "2023-03-05 07:53:26,386 - INFO - Computed 0 values for constant folding\n",
            "2023-03-05 07:53:26,467 - INFO - Optimizing ONNX model\n",
            "2023-03-05 07:53:26,543 - INFO - After optimization: BatchNormalization -6 (6->0), Cast -1 (1->0), Const -24 (43->19), Identity -9 (9->0), Transpose -28 (30->2)\n",
            "2023-03-05 07:53:26,549 - INFO - \n",
            "2023-03-05 07:53:26,549 - INFO - Successfully converted TensorFlow model /content/CadenceNet_Float/ to ONNX\n",
            "2023-03-05 07:53:26,549 - INFO - Model inputs: ['conv2d_input:0']\n",
            "2023-03-05 07:53:26,550 - INFO - Model outputs: ['softmax']\n",
            "2023-03-05 07:53:26,550 - INFO - ONNX model is saved at /content/CadenceNetOriginal_Float.onnx\n"
          ]
        }
      ],
      "source": [
        "!pip install -U tf2onnx==1.8.4\n",
        "!python -m tf2onnx.convert --saved-model /content/CadenceNet_Float/ --output /content/CadenceNetOriginal_Float.onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "-UgJyPkX5UKe",
        "outputId": "c15860fc-478f-445a-bc8d-bcc2eb6ded87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1359408"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "quant_file = \"/content/CadenceNetOriginal_QAT.tflite\"\n",
        "open(quant_file, \"wb\").write(quantized_tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "T5iITOiiRP0M",
        "outputId": "5b491708-ed48-42c5-f2cd-0b1099b2b115",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Float model in Mb:  2.1094303131103516\n",
            "Quantized model in Mb:  1.2964324951171875\n",
            "Float Model Accuracy:  0.7847\n",
            "Quantized Model Accuracy:  0.8038\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"Float model in Mb: \", os.path.getsize(\"/content/CadenceNetOriginal_Float.onnx\") / float(2**20))\n",
        "print(\"Quantized model in Mb: \", os.path.getsize(quant_file) / float(2**20))\n",
        "print(\"Float Model Accuracy: \", test_accuracy_Float)\n",
        "print(\"Quantized Model Accuracy: \", test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xh_ERgvr1BNy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}