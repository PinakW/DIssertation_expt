{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PinakW/DIssertation_expt/blob/main/Original_CadenceNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYvbodAaO5NT"
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "#For plotting the dataset\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "#Data pipeline preparation\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "#model buildingZ\n",
        "from tensorflow.keras import models\n",
        "import tensorflow.keras.utils as tfutils\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = 10\n",
        "USE_ORIGINAL = 0\n",
        "\n",
        "DataSet = 'caltech101'\n",
        "#'cifar10'\n",
        "def num_samples_per_class(ds_train, get_top_10 = False, print_all = False):\n",
        "    vals = np.unique(np.fromiter(ds_train.map(lambda x, y: y), int), return_counts=True)\n",
        "    class_list = []\n",
        "    class_hist = []\n",
        "    for val,count in zip(*vals):\n",
        "        if print_all==True:\n",
        "            print(int(val), count)\n",
        "        class_hist.append((val,count))\n",
        "    if get_top_10 == True:\n",
        "        sorted_tuple = sorted(class_hist, key=lambda t: t[-1], reverse=True)[:(NUM_CLASSES + 1)]    #+1 because we are going to remove \"backround_google\" i.e. 4\n",
        "        class_list = [x for x,y in sorted_tuple]\n",
        "    return class_list\n",
        "\n",
        "def filter_fn(x, allowed_classes:list):\n",
        "    allowed_classes = tf.constant(allowed_classes)\n",
        "    isallowed = tf.equal(allowed_classes, tf.cast(x, allowed_classes.dtype))\n",
        "    reduced_sum = tf.reduce_sum(tf.cast(isallowed, tf.float32))\n",
        "    return tf.greater(reduced_sum, tf.constant(0.))"
      ],
      "metadata": {
        "id": "bJSJfW_tPA88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ds_train = tfds.load(DataSet, split='train + test[:75%]', as_supervised=True)\n",
        "ds_train = tfds.load(DataSet, split='train + test[:75%]', as_supervised=True)\n",
        "ds_test = tfds.load(DataSet, split='test', as_supervised=True)"
      ],
      "metadata": {
        "id": "2fLIbNS2PDZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_list = num_samples_per_class(ds_train, get_top_10=True)\n",
        "if DataSet == 'caltech101':\n",
        "  display(class_list)\n",
        "  class_list = [i for i in class_list if i != 4]\n",
        "  display(class_list)\n",
        "  class_list.sort()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "QOoGq7JtPGn8",
        "outputId": "f35fcc85-9c8c-4322-c38d-d1276a2450ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[66, 1, 4, 38, 37, 95, 57, 9, 16, 54, 20]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[66, 1, 38, 37, 95, 57, 9, 16, 54, 20]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resized_ds_train = ds_train.filter(lambda x, y: filter_fn(y, class_list)) # as_supervised\n",
        "resized_ds_test = ds_test.filter(lambda x, y: filter_fn(y, class_list))"
      ],
      "metadata": {
        "id": "VeThcLypHU4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples_per_class(resized_ds_train, print_all=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DApyIbKhPISb",
        "outputId": "ada7bacb-483e-48ae-f38c-f3649caeac0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 611\n",
            "9 104\n",
            "16 101\n",
            "20 87\n",
            "37 335\n",
            "38 337\n",
            "54 92\n",
            "57 155\n",
            "66 625\n",
            "95 192\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples_per_class(resized_ds_test, print_all=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8z2tJJ3PLsE",
        "outputId": "72576bb6-dd0a-4850-f112-08ea73ab6c37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 770\n",
            "9 98\n",
            "16 93\n",
            "20 77\n",
            "37 405\n",
            "38 405\n",
            "54 84\n",
            "57 170\n",
            "66 768\n",
            "95 209\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameters\n",
        "IMG_SIZE = 60\n",
        "NUM_CHANNELS = 3\n",
        "BATCH_SIZE=128\n",
        "\n",
        "input_shape = (IMG_SIZE,IMG_SIZE,NUM_CHANNELS)\n",
        "#Relabelling to avoid issues. Note that human readability is reduced by this\n",
        "table = tf.lookup.StaticHashTable(\n",
        "    initializer=tf.lookup.KeyValueTensorInitializer(\n",
        "        keys=tf.constant(class_list, dtype=tf.int64),\n",
        "        #values=tf.constant([tfutils.to_categorical(0, num_classes=NUM_CLASSES, dtype=np.int64), tfutils.to_categorical(1, num_classes=NUM_CLASSES, dtype=np.int64), tfutils.to_categorical(2, num_classes=NUM_CLASSES, dtype=np.int64), tfutils.to_categorical(3, num_classes=NUM_CLASSES, dtype=np.int64), tfutils.to_categorical(4, num_classes=NUM_CLASSES, dtype=np.int64), tfutils.to_categorical(5, num_classes=NUM_CLASSES, dtype=np.int64), tfutils.to_categorical(6, num_classes=NUM_CLASSES, dtype=np.int64), tfutils.to_categorical(7, num_classes=NUM_CLASSES, dtype=np.int64), tfutils.to_categorical(8, num_classes=NUM_CLASSES, dtype=np.int64), tfutils.to_categorical(9, num_classes=NUM_CLASSES, dtype=np.int64)],  dtype=tf.int64),\n",
        "        values=tf.constant([0, 1, 2, 3, 4, 5, 6, 7, 8, 9],  dtype=tf.int64)\n",
        "    ),\n",
        "    default_value= tf.constant(0,  dtype=tf.int64)\n",
        ")\n",
        "\n",
        "#This function will be used in the graph execution hence @tf.function prefix\n",
        "@tf.function\n",
        "def map_func(label):\n",
        "    global class_list\n",
        "    mapped_label = table.lookup(label)\n",
        "    #print(type(mapped_label))\n",
        "    #mapped_label = tf.keras.utils.to_categorical(tf.make_ndarray(mapped_label), num_classes=NUM_CLASSES)\n",
        "    mapped_label = tf.one_hot(indices=mapped_label, depth=NUM_CLASSES)\n",
        "    print(\"Label = \" + str(label) + \"\\t\" + \"Mapped Label = \" + str(mapped_label))\n",
        "    return mapped_label\n",
        "\n",
        "#Preprocessing done as part of the graph\n",
        "resize_and_rescale = tf.keras.Sequential([\n",
        "  layers.Resizing(IMG_SIZE, IMG_SIZE),\n",
        "  layers.Rescaling(1./255)\n",
        "])\n",
        "\n",
        "resize_layer = tf.keras.Sequential([\n",
        "  layers.Resizing(IMG_SIZE, IMG_SIZE),\n",
        "])\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  layers.RandomRotation(0.2),\n",
        "])\n",
        "\n",
        "buffer_size = 30*NUM_CLASSES\n",
        "\n",
        "#Preprocessing function which invokes above graphs\n",
        "def prepare(ds, shuffle=False, augment=False, resize_only = False):\n",
        "    global buffer_size\n",
        "    global BATCH_SIZE\n",
        "    \n",
        "\n",
        "    # Resize and rescale all datasets.\n",
        "    if resize_only==True:\n",
        "        ds = ds.map(lambda x, y: (resize_layer(x), map_func(y)), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    else:\n",
        "        ds = ds.map(lambda x, y: (resize_and_rescale(x), map_func(y)), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    \n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size)\n",
        "        \n",
        "    # Batch all datasets.\n",
        "    #ds = ds.batch(BATCH_SIZE)\n",
        "\n",
        "    # Use data augmentation only on the training set.\n",
        "    if augment:\n",
        "        #f_ds = ds.filter(lambda x, y: filter_fn(y, [2,3,6]))    #[2,3,6] are the examples with lesser data. We are trying to bring back balance\n",
        "        #f_ds_aug = f_ds.map(lambda x, y: (data_augmentation(x, training=True), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "        #ds = ds.concatenate(f_ds_aug)\n",
        "        #ds_aug = ds.map(lambda x, y: (data_augmentation(x, training=True), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "        #ds = ds.concatenate(ds_aug)\n",
        "        ds_aug = ds.map(lambda x, y: (data_augmentation(x, training=True), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "        ds = ds.concatenate(ds_aug)\n",
        "\n",
        "        \n",
        "    # Use buffered prefetching on all datasets.\n",
        "    return ds.prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "QdPKLGVdPNrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resized_ds_train = prepare(resized_ds_train, augment=True)\n",
        "resized_ds_test = prepare(resized_ds_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmLFCHD6PgLw",
        "outputId": "93009923-e7d7-4136-dec4-50716951786d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label = Tensor(\"label:0\", shape=(), dtype=int64)\tMapped Label = Tensor(\"one_hot:0\", shape=(10,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for example in resized_ds_train.take(1):\n",
        "  plt.imshow(example[0])\n",
        "  display((example[-1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "eBn0xUIRPizz",
        "outputId": "462475c4-90a1-40b9-b6a7-e56ad9ea1138"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#num_samples_per_class(resized_ds_test, print_all=True)"
      ],
      "metadata": {
        "id": "ktMrJP5GPkUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reg = tf.keras.regularizers.L2(0.01)\n",
        "reg = tf.keras.regularizers.L1L2(l1 =0.01, l2 = 0.1)\n",
        "#beta_regularizer = 0.1\n",
        "#gamma_regularizer = 0.1\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "if USE_ORIGINAL == 1:\n",
        "  \t\n",
        "\tkernel_size = (5,5)\n",
        "\tmodel.add(layers.Conv2D(64, kernel_size, input_shape = input_shape, padding=\"same\", kernel_regularizer = reg))       #TODO: For instance, after a Conv2D layer with data_format=\"channels_first\", set axis=1 in BatchNormalization.\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tpool_size = (2,2)\n",
        "\tmodel.add(layers.MaxPool2D(pool_size))\n",
        "\tmodel.add(layers.Dropout(.2))\n",
        "\t\n",
        "\tkernel_size = (3,3)\n",
        "\tmodel.add(layers.Conv2D(192, kernel_size, padding=\"same\", kernel_regularizer = reg))      #TODO: For instance, after a Conv2D layer with data_format=\"channels_first\", set axis=1 in BatchNormalization.\n",
        "\tmodel.add(layers.BatchNormalization())                                                      #beta_regularizer = beta_regularizer, gamma_regularizer = gamma_regularizer\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tpool_size = (2,2)\n",
        "\tmodel.add(layers.MaxPool2D(pool_size))\n",
        "\tmodel.add(layers.Dropout(.2))\n",
        "\t#model.add(layers.SpatialDropout2D(0.2))\n",
        "\t\n",
        "\tkernel_size = (3,3)\n",
        "\tmodel.add(layers.Conv2D(64, kernel_size, padding=\"same\", kernel_regularizer = reg))       #TODO: For instance, after a Conv2D layer with data_format=\"channels_first\", set axis=1 in BatchNormalization.\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.Dropout(.2))\n",
        "\t\n",
        "\tkernel_size = (3,3)\n",
        "\tmodel.add(layers.Conv2D(128, kernel_size, padding=\"same\", kernel_regularizer = reg))      #TODO: For instance, after a Conv2D layer with data_format=\"channels_first\", set axis=1 in BatchNormalization.\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tpool_size = (2,2)\n",
        "\tmodel.add(layers.MaxPool2D(pool_size))\n",
        "\tmodel.add(layers.Dropout(.2))\n",
        "\t#model.add(layers.SpatialDropout2D(0.2))\n",
        "\t\n",
        "\tmodel.add(layers.Flatten())\n",
        "\tmodel.add(layers.Dropout(.2))\n",
        "\tmodel.add(layers.Dense(NUM_CLASSES, activation='softmax', kernel_regularizer = reg))\n",
        "else:\n",
        "  kernel_size = (5,5)\n",
        "  model.add(layers.Conv2D(32, kernel_size, input_shape = input_shape, padding=\"same\", kernel_regularizer = reg))       #TODO: For instance, after a Conv2D layer with data_format=\"channels_first\", set axis=1 in BatchNormalization.\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "#  model.add(layers.ReLU())\n",
        "\tpool_size = (2,2)\n",
        "\tmodel.add(layers.MaxPool2D(pool_size))\n",
        "\t\n",
        "\tkernel_size = (3,3)\n",
        "\tmodel.add(layers.Conv2D(64, kernel_size, padding=\"same\", kernel_regularizer = reg))      #TODO: For instance, after a Conv2D layer with data_format=\"channels_first\", set axis=1 in BatchNormalization.\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "#  model.add(layers.ReLU())\n",
        "\tpool_size = (2,2)\n",
        "\tmodel.add(layers.MaxPool2D(pool_size))\n",
        "\t\n",
        "\tkernel_size = (3,3)\n",
        "\tmodel.add(layers.Conv2D(128, kernel_size, padding=\"same\", kernel_regularizer = reg))       #TODO: For instance, after a Conv2D layer with data_format=\"channels_first\", set axis=1 in BatchNormalization.\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "#  model.add(layers.ReLU())\n",
        "\tpool_size = (2,2)\n",
        "\tmodel.add(layers.MaxPool2D(pool_size))\n",
        "\t\n",
        "\tkernel_size = (3,3)\n",
        "\tmodel.add(layers.Conv2D(192, kernel_size, padding=\"same\", kernel_regularizer = reg))      #TODO: For instance, after a Conv2D layer with data_format=\"channels_first\", set axis=1 in BatchNormalization.\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "#  model.add(layers.ReLU())\n",
        "\tpool_size = (2,2)\n",
        "\tmodel.add(layers.MaxPool2D(pool_size))\n",
        "\t\n",
        "\tkernel_size = (3,3)\n",
        "\tmodel.add(layers.Conv2D(64, kernel_size, padding=\"same\", kernel_regularizer = reg))      #TODO: For instance, after a Conv2D layer with data_format=\"channels_first\", set axis=1 in BatchNormalization.\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "#  model.add(layers.ReLU())\n",
        "\tpool_size = (2,2)\n",
        "\tmodel.add(layers.MaxPool2D(pool_size))\n",
        "\t\n",
        "\tkernel_size = (3,3)\n",
        "\tmodel.add(layers.Conv2D(32, kernel_size, padding=\"same\", kernel_regularizer = reg))      #TODO: For instance, after a Conv2D layer with data_format=\"channels_first\", set axis=1 in BatchNormalization.\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "#  model.add(layers.ReLU())\n",
        "\tpool_size = (2,2)\n",
        "\tmodel.add(layers.MaxPool2D(pool_size))\n",
        "\t\n",
        "\tmodel.add(layers.Flatten())\n",
        "\tmodel.add(layers.Dropout(.2))\n",
        "\tmodel.add(layers.Dense(1000, kernel_regularizer = reg))\n",
        "\tmodel.add(layers.Dropout(.02))\n",
        "\tmodel.add(layers.Dense(NUM_CLASSES, activation='softmax', kernel_regularizer = reg))"
      ],
      "metadata": {
        "id": "ftnZ5OyvQB98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Learning_Rate = 1e-5                                           \n",
        "opt = tf.keras.optimizers.Adam(learning_rate=Learning_Rate)     #OR tf.keras.optimizers.SGD(learning_rate=Learning_Rate, momentum=0.0)\n",
        "#model.compile( optimizer = opt, loss = 'sparse_categorical_crossentropy', metrics=['accuracy'] )\n",
        "model.compile( optimizer = opt, loss = 'categorical_crossentropy', metrics=['categorical_accuracy'] )\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpzOv6ADQP8L",
        "outputId": "f296af72-4f9d-498f-acb2-f9e1f0fb14b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_49\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_28 (Conv2D)          (None, 60, 60, 64)        4864      \n",
            "                                                                 \n",
            " batch_normalization_28 (Bat  (None, 60, 60, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_28 (ReLU)             (None, 60, 60, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_21 (MaxPoolin  (None, 30, 30, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 30, 30, 64)        0         \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (None, 30, 30, 192)       110784    \n",
            "                                                                 \n",
            " batch_normalization_29 (Bat  (None, 30, 30, 192)      768       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_29 (ReLU)             (None, 30, 30, 192)       0         \n",
            "                                                                 \n",
            " max_pooling2d_22 (MaxPoolin  (None, 15, 15, 192)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 15, 15, 192)       0         \n",
            "                                                                 \n",
            " conv2d_30 (Conv2D)          (None, 15, 15, 64)        110656    \n",
            "                                                                 \n",
            " batch_normalization_30 (Bat  (None, 15, 15, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_30 (ReLU)             (None, 15, 15, 64)        0         \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 15, 15, 64)        0         \n",
            "                                                                 \n",
            " conv2d_31 (Conv2D)          (None, 15, 15, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_31 (Bat  (None, 15, 15, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_31 (ReLU)             (None, 15, 15, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d_23 (MaxPoolin  (None, 7, 7, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 6272)              0         \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 6272)              0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                62730     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 364,682\n",
            "Trainable params: 363,786\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#h = model.fit( resized_ds_train, epochs=10)\n",
        "resized_ds_train = resized_ds_train.batch(BATCH_SIZE)\n",
        "resized_ds_test = resized_ds_test.batch(BATCH_SIZE)\n",
        "\n",
        "h = model.fit( resized_ds_train, epochs=20, validation_data = resized_ds_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKoB4BcEQVkU",
        "outputId": "f9356627-14e3-4de9-d3d0-2f3a9c0110be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "42/42 [==============================] - 8s 162ms/step - loss: 122.0017 - categorical_accuracy: 0.1747 - val_loss: 120.6249 - val_categorical_accuracy: 0.3293\n",
            "Epoch 2/20\n",
            "42/42 [==============================] - 6s 151ms/step - loss: 120.2942 - categorical_accuracy: 0.2730 - val_loss: 119.3555 - val_categorical_accuracy: 0.2475\n",
            "Epoch 3/20\n",
            "42/42 [==============================] - 6s 151ms/step - loss: 118.8379 - categorical_accuracy: 0.3299 - val_loss: 118.0750 - val_categorical_accuracy: 0.2498\n",
            "Epoch 4/20\n",
            "42/42 [==============================] - 6s 151ms/step - loss: 117.4226 - categorical_accuracy: 0.3611 - val_loss: 116.7996 - val_categorical_accuracy: 0.2498\n",
            "Epoch 5/20\n",
            "42/42 [==============================] - 6s 153ms/step - loss: 116.0180 - categorical_accuracy: 0.3876 - val_loss: 115.5234 - val_categorical_accuracy: 0.2494\n",
            "Epoch 6/20\n",
            "42/42 [==============================] - 6s 154ms/step - loss: 114.6120 - categorical_accuracy: 0.4159 - val_loss: 114.2192 - val_categorical_accuracy: 0.2498\n",
            "Epoch 7/20\n",
            "42/42 [==============================] - 6s 155ms/step - loss: 113.2035 - categorical_accuracy: 0.4390 - val_loss: 112.8867 - val_categorical_accuracy: 0.2514\n",
            "Epoch 8/20\n",
            "42/42 [==============================] - 7s 156ms/step - loss: 111.8058 - categorical_accuracy: 0.4513 - val_loss: 111.5086 - val_categorical_accuracy: 0.2618\n",
            "Epoch 9/20\n",
            "24/42 [================>.............] - ETA: 1s - loss: 110.5928 - categorical_accuracy: 0.4967"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(h.history['loss'])\n",
        "plt.plot(h.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FuOyiBsTQkYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ret_as_numpy():\n",
        "    test = tfds.load(DataSet, split='test', as_supervised=True)\n",
        "    test = prepare(test)\n",
        "    test = tfds.as_numpy(test)\n",
        "    return test"
      ],
      "metadata": {
        "id": "7NaFdDuTQoyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_as_np = ret_as_numpy()"
      ],
      "metadata": {
        "id": "Si_MguzMQuZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_float_model(model, test):\n",
        "    test_labels = []\n",
        "    \n",
        "    # Run predictions on every image in the \"test\" dataset.\n",
        "    prediction_digits = []\n",
        "    for i, test_example in enumerate(test):\n",
        "        if i % 1000 == 0:\n",
        "            print('Evaluated on {n} results so far.'.format(n=i))\n",
        "        test_labels.append(test_example[-1])\n",
        "        test_image = test_example[0]\n",
        "        # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "        # the model's input data format.\n",
        "        #display(test_image.shape)\n",
        "        test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "        #test_image = np.expand_dims(test_image, axis=3).astype(np.float32)\n",
        "        #display(test_image.shape)\n",
        "        \n",
        "        # Run inference.\n",
        "        output = model(test_image, training=False)\n",
        "        # Post-processing: remove batch dimension and find the digit with highest\n",
        "        # probability.\n",
        "        output = output.numpy()\n",
        "        #display(output[0])\n",
        "        digit = np.argmax(output[0])\n",
        "        prediction_digits.append(digit)\n",
        "        \n",
        "    print('\\n')\n",
        "    # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "    #display(prediction_digits)\n",
        "    #display(test_labels)\n",
        "    prediction_digits = np.array(prediction_digits)\n",
        "    accuracy = (prediction_digits == test_labels).mean()\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "xWYWlODgQrFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy_Float = evaluate_float_model(model, test_as_np)\n",
        "\n",
        "print('Float test_accuracy:', test_accuracy_Float)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "id": "BOHIU_J3QxE7",
        "outputId": "a0187a01-f70e-4459-83c7-7e6fdabcc6ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluated on 0 results so far.\n",
            "Evaluated on 1000 results so far.\n",
            "Evaluated on 2000 results so far.\n",
            "Evaluated on 3000 results so far.\n",
            "Evaluated on 4000 results so far.\n",
            "Evaluated on 5000 results so far.\n",
            "Evaluated on 6000 results so far.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-177-233a3bd68f0e>:32: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  accuracy = (prediction_digits == test_labels).mean()\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-178-fbc58c3a1cb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_accuracy_Float\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_float_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_as_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Float test_accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy_Float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-177-233a3bd68f0e>\u001b[0m in \u001b[0;36mevaluate_float_model\u001b[0;34m(model, test)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m#display(test_labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mprediction_digits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_digits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprediction_digits\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'bool' object has no attribute 'mean'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Float checkpoint"
      ],
      "metadata": {
        "id": "g_Q2Is9IY-Oo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q tensorflow-model-optimization\n",
        "import tensorflow_model_optimization as tfmot\n",
        "quantize_model = tfmot.quantization.keras.quantize_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fr6QAx7Qztb",
        "outputId": "c7e52758-d331-400c-d193-795fcd194a4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/238.9 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m174.1/238.9 KB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.9/238.9 KB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q_aware_model = quantize_model(model)\n",
        "q_aware_model.compile(optimizer = opt, loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "q_aware_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfG_qAU4Q3DL",
        "outputId": "7a917bf0-6470-4021-9bd9-124d52dde786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " quantize_layer (QuantizeLay  (None, 60, 60, 3)        3         \n",
            " er)                                                             \n",
            "                                                                 \n",
            " quant_conv2d (QuantizeWrapp  (None, 60, 60, 64)       4993      \n",
            " erV2)                                                           \n",
            "                                                                 \n",
            " quant_batch_normalization (  (None, 60, 60, 64)       257       \n",
            " QuantizeWrapperV2)                                              \n",
            "                                                                 \n",
            " quant_re_lu (QuantizeWrappe  (None, 60, 60, 64)       3         \n",
            " rV2)                                                            \n",
            "                                                                 \n",
            " quant_max_pooling2d (Quanti  (None, 30, 30, 64)       1         \n",
            " zeWrapperV2)                                                    \n",
            "                                                                 \n",
            " quant_conv2d_1 (QuantizeWra  (None, 30, 30, 192)      111169    \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            " quant_batch_normalization_1  (None, 30, 30, 192)      769       \n",
            "  (QuantizeWrapperV2)                                            \n",
            "                                                                 \n",
            " quant_re_lu_1 (QuantizeWrap  (None, 30, 30, 192)      3         \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            " quant_max_pooling2d_1 (Quan  (None, 15, 15, 192)      1         \n",
            " tizeWrapperV2)                                                  \n",
            "                                                                 \n",
            " quant_conv2d_2 (QuantizeWra  (None, 15, 15, 64)       110785    \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            " quant_batch_normalization_2  (None, 15, 15, 64)       257       \n",
            "  (QuantizeWrapperV2)                                            \n",
            "                                                                 \n",
            " quant_re_lu_2 (QuantizeWrap  (None, 15, 15, 64)       3         \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            " quant_conv2d_3 (QuantizeWra  (None, 15, 15, 128)      74113     \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            " quant_batch_normalization_3  (None, 15, 15, 128)      513       \n",
            "  (QuantizeWrapperV2)                                            \n",
            "                                                                 \n",
            " quant_re_lu_3 (QuantizeWrap  (None, 15, 15, 128)      3         \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            " quant_max_pooling2d_2 (Quan  (None, 7, 7, 128)        1         \n",
            " tizeWrapperV2)                                                  \n",
            "                                                                 \n",
            " quant_flatten (QuantizeWrap  (None, 6272)             1         \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            " quant_dropout (QuantizeWrap  (None, 6272)             1         \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            " quant_dense (QuantizeWrappe  (None, 10)               62735     \n",
            " rV2)                                                            \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 365,611\n",
            "Trainable params: 363,786\n",
            "Non-trainable params: 1,825\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quantize_train, quant_train_info = tfds.load(DataSet, split='train + test[:75%]', with_info=True, as_supervised=True)\n",
        "filtered_quantize_train = quantize_train.filter(lambda x, y: filter_fn(y, class_list))\n",
        "\n",
        "resized_quantize_train = prepare(filtered_quantize_train)"
      ],
      "metadata": {
        "id": "AYdW-VK8Q5mT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resized_quantize_train = resized_quantize_train.batch(BATCH_SIZE)\n",
        "h = q_aware_model.fit(resized_quantize_train, epochs=5, validation_data = resized_ds_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VQBS_obQ8DF",
        "outputId": "dcb58445-2f3f-4233-bd32-729718614dae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "23/23 [==============================] - 11s 410ms/step - loss: 103.5816 - accuracy: 0.7253 - val_loss: 102.2401 - val_accuracy: 0.5522\n",
            "Epoch 2/5\n",
            "23/23 [==============================] - 6s 274ms/step - loss: 100.2163 - accuracy: 0.7621 - val_loss: 99.2292 - val_accuracy: 0.6013\n",
            "Epoch 3/5\n",
            "23/23 [==============================] - 6s 249ms/step - loss: 97.5099 - accuracy: 0.7906 - val_loss: 96.7705 - val_accuracy: 0.6351\n",
            "Epoch 4/5\n",
            "23/23 [==============================] - 6s 245ms/step - loss: 95.2851 - accuracy: 0.8003 - val_loss: 94.6298 - val_accuracy: 0.6976\n",
            "Epoch 5/5\n",
            "23/23 [==============================] - 4s 163ms/step - loss: 93.3335 - accuracy: 0.8161 - val_loss: 92.7477 - val_accuracy: 0.7188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(h.history['loss'])\n",
        "plt.plot(h.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "pHskuvDaRBPb",
        "outputId": "8b49e910-c4aa-4b3c-bb99-db2249cdb648"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "quantized_tflite_model = converter.convert()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFq4nw4PRDYT",
        "outputId": "b6dc2c23-ede9-46de-8277-59a284d700cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses while saving (showing 5 of 26). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/lite/python/convert.py:766: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(interpreter, test):\n",
        "    test_labels = []\n",
        "\n",
        "\n",
        "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "    \n",
        "    # Run predictions on every image in the \"test\" dataset.\n",
        "    prediction_digits = []\n",
        "    for i, test_example in enumerate(test):\n",
        "        if i % 1000 == 0:\n",
        "            print('Evaluated on {n} results so far.'.format(n=i))\n",
        "        test_labels.append(test_example[-1])\n",
        "        test_image = test_example[0]\n",
        "        # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "        # the model's input data format.\n",
        "        #display(test_image.shape)\n",
        "        test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "        #test_image = np.expand_dims(test_image, axis=3).astype(np.float32)\n",
        "        #display(test_image.shape)\n",
        "        interpreter.set_tensor(input_index, test_image)\n",
        "        \n",
        "        # Run inference.\n",
        "        interpreter.invoke()\n",
        "        \n",
        "        # Post-processing: remove batch dimension and find the digit with highest\n",
        "        # probability.\n",
        "        output = interpreter.tensor(output_index)\n",
        "        digit = np.argmax(output()[0])\n",
        "        prediction_digits.append(digit)\n",
        "        \n",
        "    print('\\n')\n",
        "    # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "    prediction_digits = np.array(prediction_digits)\n",
        "    accuracy = (prediction_digits == test_labels).mean()\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "bJbUyvBrRGBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Models obtained from TfLiteConverter can be run in Python with Interpreter.\n",
        "interpreter = tf.lite.Interpreter(model_content=quantized_tflite_model)\n",
        "#Since TensorFlow Lite pre-plans tensor allocations to optimize inference, the user needs to call allocate_tensors() before any inference.\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "test_accuracy = evaluate_model(interpreter, test_as_np)\n",
        "\n",
        "print('Quant TFLite test_accuracy:', test_accuracy)\n",
        "#print('Quant TF test accuracy:', q_aware_model_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ol3wMK2RIjN",
        "outputId": "81b9818a-ffcb-4ba9-f053-8aa934297400"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluated on 0 results so far.\n",
            "Evaluated on 1000 results so far.\n",
            "Evaluated on 2000 results so far.\n",
            "Evaluated on 3000 results so far.\n",
            "Evaluated on 4000 results so far.\n",
            "Evaluated on 5000 results so far.\n",
            "Evaluated on 6000 results so far.\n",
            "\n",
            "\n",
            "Quant TFLite test_accuracy: 0.5698553583168968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_DIR = \"CadenceNet_Float\"\n",
        "model.save(MODEL_DIR, save_format=\"tf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVX3TFb5RKeD",
        "outputId": "12845ef5-554d-44fc-8910-35f37ff18556"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U tf2onnx\n",
        "!python -m tf2onnx.convert --saved-model /content/CadenceNet_Float/ --output /content/CadenceNetOriginal_Float.onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKEqxRdmRMOL",
        "outputId": "050f2fcd-3f2b-48ba-d003-851e8b2ffe9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tf2onnx\n",
            "  Downloading tf2onnx-1.13.0-py3-none-any.whl (442 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.3/442.3 KB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from tf2onnx) (1.15.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tf2onnx) (1.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from tf2onnx) (2.25.1)\n",
            "Requirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.8/dist-packages (from tf2onnx) (1.21.6)\n",
            "Collecting onnx>=1.4.1\n",
            "  Downloading onnx-1.13.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.8/dist-packages (from onnx>=1.4.1->tf2onnx) (4.4.0)\n",
            "Collecting protobuf<4,>=3.20.2\n",
            "  Downloading protobuf-3.20.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->tf2onnx) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->tf2onnx) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->tf2onnx) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->tf2onnx) (2022.12.7)\n",
            "Installing collected packages: protobuf, onnx, tf2onnx\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.19.6\n",
            "    Uninstalling protobuf-3.19.6:\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m/usr/bin/python3: Error while finding module specification for 'tf2onnx.convert' (ModuleNotFoundError: No module named 'tf2onnx')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quant_file = \"/content/CadenceNetOriginal_QAT.tflite\"\n",
        "open(quant_file, \"wb\").write(quantized_tflite_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLDe9u9sRORk",
        "outputId": "01812551-c9d9-4815-f252-be65a7f871e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "381680"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Float model in Mb: \", os.path.getsize(\"/content/CadenceNetOriginal_Float.onnx\") / float(2**20))\n",
        "print(\"Quantized model in Mb: \", os.path.getsize(quant_file) / float(2**20))\n",
        "print(\"Float Model Accuracy: \", test_accuracy_Float)\n",
        "print(\"Quantized Model Accuracy: \", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "T5iITOiiRP0M",
        "outputId": "5bf39ad3-f2fd-4459-e679-2b7e440e006a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-13531ae925b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Float model in Mb: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/CadenceNetOriginal_Float.onnx\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Quantized model in Mb: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquant_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Float Model Accuracy: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy_Float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Quantized Model Accuracy: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/genericpath.py\u001b[0m in \u001b[0;36mgetsize\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;34m\"\"\"Return the size of a file, reported by os.stat().\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/CadenceNetOriginal_Float.onnx'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indices = [0, 1, 2]\n",
        "depth = 3\n",
        "label = tf.one_hot(indices, depth)\n",
        "print(str(label))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_byw6-0Um7c",
        "outputId": "09c15091-d672-44e5-c13f-09525ae35360"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]], shape=(3, 3), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AwinLylaUv3f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}